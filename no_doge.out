nohup: ignoring input
wandb: Currently logged in as: ruben-navasardyan4869 (ruben-navasardyan4869-epfl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /mloscratch/homes/navasard/moe_doge/llm-baselines-moe/wandb/run-20250915_222559-h9va4olf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run base_lr0.001_bs32x4_seqlen512/no_doge=True_run_id=20250915_222420_seed=0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ruben-navasardyan4869-epfl/token-mix-moe
wandb: üöÄ View run at https://wandb.ai/ruben-navasardyan4869-epfl/token-mix-moe/runs/h9va4olf
wandb: WARNING Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 2000 that is less than the current step 2001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 3000 that is less than the current step 3001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 4000 that is less than the current step 4001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 5000 that is less than the current step 5001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 6000 that is less than the current step 6001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 7000 that is less than the current step 7001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 8000 that is less than the current step 8001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 9000 that is less than the current step 9001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 10000 that is less than the current step 10001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 11000 that is less than the current step 11001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 12000 that is less than the current step 12001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 13000 that is less than the current step 13001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 14000 that is less than the current step 14001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 15000 that is less than the current step 15001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 16000 that is less than the current step 16001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 17000 that is less than the current step 17001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 18000 that is less than the current step 18001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 19000 that is less than the current step 19001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 20000 that is less than the current step 20001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 21000 that is less than the current step 21001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 22000 that is less than the current step 22001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 23000 that is less than the current step 23001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 24000 that is less than the current step 24001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 25000 that is less than the current step 25001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 26000 that is less than the current step 26001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 27000 that is less than the current step 27001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 28000 that is less than the current step 28001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 29000 that is less than the current step 29001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 30000 that is less than the current step 30001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 31000 that is less than the current step 31001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 32000 that is less than the current step 32001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 33000 that is less than the current step 33001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 34000 that is less than the current step 34001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 35000 that is less than the current step 35001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 36000 that is less than the current step 36001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 37000 that is less than the current step 37001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 38000 that is less than the current step 38001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 39000 that is less than the current step 39001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 40000 that is less than the current step 40001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 41000 that is less than the current step 41001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 42000 that is less than the current step 42001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 43000 that is less than the current step 43001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 44000 that is less than the current step 44001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 45000 that is less than the current step 45001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 46000 that is less than the current step 46001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 47000 that is less than the current step 47001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 48000 that is less than the current step 48001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 49000 that is less than the current step 49001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 50000 that is less than the current step 50001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 51000 that is less than the current step 51001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 52000 that is less than the current step 52001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 53000 that is less than the current step 53001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 54000 that is less than the current step 54001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 55000 that is less than the current step 55001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 56000 that is less than the current step 56001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 57000 that is less than the current step 57001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 58000 that is less than the current step 58001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 59000 that is less than the current step 59001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 60000 that is less than the current step 60001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 61000 that is less than the current step 61001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 62000 that is less than the current step 62001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 63000 that is less than the current step 63001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 64000 that is less than the current step 64001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 65000 that is less than the current step 65001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 66000 that is less than the current step 66001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 67000 that is less than the current step 67001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 68000 that is less than the current step 68001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 69000 that is less than the current step 69001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 70000 that is less than the current step 70001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 71000 that is less than the current step 71001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 72000 that is less than the current step 72001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 73000 that is less than the current step 73001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 74000 that is less than the current step 74001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 75000 that is less than the current step 75001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 76000 that is less than the current step 76001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 77000 that is less than the current step 77001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 78000 that is less than the current step 78001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 79000 that is less than the current step 79001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 80000 that is less than the current step 80001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 81000 that is less than the current step 81001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 82000 that is less than the current step 82001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 83000 that is less than the current step 83001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 84000 that is less than the current step 84001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 85000 that is less than the current step 85001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 86000 that is less than the current step 86001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 87000 that is less than the current step 87001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 88000 that is less than the current step 88001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 89000 that is less than the current step 89001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 90000 that is less than the current step 90001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 91000 that is less than the current step 91001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 92000 that is less than the current step 92001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 93000 that is less than the current step 93001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 94000 that is less than the current step 94001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 95000 that is less than the current step 95001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 96000 that is less than the current step 96001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 97000 that is less than the current step 97001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 98000 that is less than the current step 98001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 99000 that is less than the current step 99001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Loading dataset 'slimpajama'
Num training tokens: 6553600001
Num validation tokens: 196214785
number of parameters: 255.71M
number of optimized parameters: 256.11M
using fused AdamW: True

Training model=base 
{'config_format': 'base', 'batch_size': 32, 'acc_steps': 4, 'seed': 0, 'data_seed': 1004, 'device': device(type='cuda', index=0), 'iterations': 100000, 'lr': 0.001, 'warmup_percent': 0.05, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'scheduler': 'cos', 'opt': 'adamw', 'eval_freq': 200, 'results_base_folder': './exps', 'grad_clip': 0.0, 'dataset': 'slimpajama', 'vocab_size': 50304, 'data_in_ram': False, 'model': 'base', 'use_pretrained': None, 'dropout': 0.0, 'n_head': 6, 'n_layer': 12, 'n_embd': 768, 'sequence_length': 512, 'dtype': torch.bfloat16, 'bias': False, 'compile': False, 'rmsnorm_eps': 1e-05, 'moe_num_experts': 7, 'moe_num_experts_per_tok': 1, 'moe_softmax_order': 'softmax_topk', 'moe_type': 'token_choice', 'mlp_dim_exp_factor': 4, 'moe_entropy_loss_factor': 0.001, 'moe_aux_loss_factor': 0.01, 'moe_z_loss_factor': 0.001, 'no_doge': True, 'moe_router_loss': 'load_balancing_only', 'multiple_of': 256, 'run_prefix': None, 'exp_name': 'base_lr0.001_bs32x4_seqlen512/no_doge=True_run_id=20250915_222420_seed=0', 'wandb': True, 'wandb_project': 'token-mix-moe', 'wandb_run_prefix': 'none', 'eval_seq_prefix': 'Once upon a time', 'undefine_run_id': False, 'distributed_backend': None, 'save_checkpoint_freq': None, 'run_id': '20250915_222420', 'world_size': 1}

0/200 [train] loss=8.061 [val] loss=8.033, pp=3080.85, acc=0.113589 [time per itr] 148.26ms [lr] 0.00001
0/400 [train] loss=7.243 [val] loss=7.089, pp=1198.41, acc=0.141874 [time per itr] 226.77ms [lr] 0.00003
0/600 [train] loss=6.939 [val] loss=6.766, pp=868.18, acc=0.141411 [time per itr] 395.34ms [lr] 0.00004
0/800 [train] loss=6.738 [val] loss=6.435, pp=623.54, acc=0.154844 [time per itr] 348.34ms [lr] 0.00007
0/1000 [train] loss=6.007 [val] loss=6.211, pp=498.38, acc=0.167442 [time per itr] 304.05ms [lr] 0.00010
0/1200 [train] loss=5.920 [val] loss=6.035, pp=417.99, acc=0.176216 [time per itr] 272.41ms [lr] 0.00014
0/1400 [train] loss=5.729 [val] loss=5.887, pp=360.35, acc=0.182953 [time per itr] 243.00ms [lr] 0.00019
0/1600 [train] loss=5.748 [val] loss=5.722, pp=305.46, acc=0.192785 [time per itr] 228.78ms [lr] 0.00024
0/1800 [train] loss=5.683 [val] loss=5.665, pp=288.54, acc=0.197164 [time per itr] 207.59ms [lr] 0.00029
0/2000 [train] loss=5.578 [val] loss=5.480, pp=239.95, acc=0.208776 [time per itr] 198.11ms [lr] 0.00035
0/2200 [train] loss=5.527 [val] loss=5.256, pp=191.62, acc=0.234769 [time per itr] 196.12ms [lr] 0.00041
0/2400 [train] loss=5.278 [val] loss=5.209, pp=182.97, acc=0.236191 [time per itr] 182.41ms [lr] 0.00047
0/2600 [train] loss=4.997 [val] loss=5.135, pp=169.90, acc=0.246938 [time per itr] 183.32ms [lr] 0.00054
0/2800 [train] loss=4.882 [val] loss=5.054, pp=156.60, acc=0.254860 [time per itr] 180.48ms [lr] 0.00060
0/3000 [train] loss=4.916 [val] loss=4.972, pp=144.31, acc=0.260874 [time per itr] 165.33ms [lr] 0.00066
0/3200 [train] loss=4.623 [val] loss=4.891, pp=133.11, acc=0.269931 [time per itr] 162.92ms [lr] 0.00072
0/3400 [train] loss=5.202 [val] loss=4.896, pp=133.74, acc=0.268595 [time per itr] 161.28ms [lr] 0.00077
0/3600 [train] loss=4.781 [val] loss=4.763, pp=117.14, acc=0.285431 [time per itr] 159.58ms [lr] 0.00082
0/3800 [train] loss=4.792 [val] loss=4.784, pp=119.63, acc=0.279762 [time per itr] 158.30ms [lr] 0.00087
0/4000 [train] loss=4.817 [val] loss=4.802, pp=121.81, acc=0.277982 [time per itr] 155.05ms [lr] 0.00091
0/4200 [train] loss=4.760 [val] loss=4.736, pp=114.02, acc=0.280487 [time per itr] 153.43ms [lr] 0.00094
0/4400 [train] loss=4.281 [val] loss=4.706, pp=110.59, acc=0.283918 [time per itr] 152.93ms [lr] 0.00097
0/4600 [train] loss=4.497 [val] loss=4.724, pp=112.60, acc=0.281820 [time per itr] 154.96ms [lr] 0.00098
0/4800 [train] loss=4.661 [val] loss=4.634, pp=102.93, acc=0.291150 [time per itr] 154.05ms [lr] 0.00100
0/5000 [train] loss=4.482 [val] loss=4.596, pp=99.08, acc=0.294479 [time per itr] 152.02ms [lr] 0.00100
0/5200 [train] loss=4.574 [val] loss=4.503, pp=90.29, acc=0.305517 [time per itr] 155.35ms [lr] 0.00100
0/5400 [train] loss=4.460 [val] loss=4.581, pp=97.65, acc=0.292781 [time per itr] 151.59ms [lr] 0.00100
0/5600 [train] loss=4.712 [val] loss=4.513, pp=91.20, acc=0.303836 [time per itr] 149.94ms [lr] 0.00100
0/5800 [train] loss=4.348 [val] loss=4.496, pp=89.69, acc=0.304316 [time per itr] 148.35ms [lr] 0.00100
0/6000 [train] loss=4.327 [val] loss=4.498, pp=89.81, acc=0.301852 [time per itr] 148.17ms [lr] 0.00100
0/6200 [train] loss=4.533 [val] loss=4.414, pp=82.60, acc=0.310287 [time per itr] 148.37ms [lr] 0.00100
0/6400 [train] loss=4.398 [val] loss=4.450, pp=85.66, acc=0.308935 [time per itr] 147.06ms [lr] 0.00100
0/6600 [train] loss=4.542 [val] loss=4.398, pp=81.31, acc=0.310277 [time per itr] 146.41ms [lr] 0.00100
0/6800 [train] loss=4.332 [val] loss=4.323, pp=75.41, acc=0.321673 [time per itr] 147.31ms [lr] 0.00100
0/7000 [train] loss=4.255 [val] loss=4.381, pp=79.93, acc=0.311841 [time per itr] 146.32ms [lr] 0.00100
0/7200 [train] loss=4.126 [val] loss=4.408, pp=82.13, acc=0.306928 [time per itr] 146.90ms [lr] 0.00100
0/7400 [train] loss=4.517 [val] loss=4.289, pp=72.88, acc=0.323667 [time per itr] 146.43ms [lr] 0.00100
0/7600 [train] loss=4.595 [val] loss=4.347, pp=77.22, acc=0.317970 [time per itr] 146.85ms [lr] 0.00100
0/7800 [train] loss=4.233 [val] loss=4.328, pp=75.79, acc=0.320274 [time per itr] 145.60ms [lr] 0.00100
0/8000 [train] loss=4.470 [val] loss=4.272, pp=71.68, acc=0.327563 [time per itr] 146.07ms [lr] 0.00100
0/8200 [train] loss=4.263 [val] loss=4.305, pp=74.05, acc=0.319115 [time per itr] 145.76ms [lr] 0.00100
0/8400 [train] loss=4.221 [val] loss=4.277, pp=72.02, acc=0.325450 [time per itr] 148.36ms [lr] 0.00100
0/8600 [train] loss=4.430 [val] loss=4.303, pp=73.93, acc=0.319819 [time per itr] 148.69ms [lr] 0.00100
0/8800 [train] loss=4.316 [val] loss=4.239, pp=69.30, acc=0.329549 [time per itr] 154.94ms [lr] 0.00100
0/9000 [train] loss=4.407 [val] loss=4.231, pp=68.78, acc=0.328069 [time per itr] 149.62ms [lr] 0.00100
0/9200 [train] loss=3.973 [val] loss=4.245, pp=69.75, acc=0.326859 [time per itr] 147.02ms [lr] 0.00100
0/9400 [train] loss=4.084 [val] loss=4.190, pp=66.05, acc=0.333616 [time per itr] 145.63ms [lr] 0.00100
0/9600 [train] loss=3.948 [val] loss=4.245, pp=69.75, acc=0.326383 [time per itr] 145.83ms [lr] 0.00099
0/9800 [train] loss=4.249 [val] loss=4.227, pp=68.54, acc=0.325534 [time per itr] 147.34ms [lr] 0.00099
0/10000 [train] loss=4.234 [val] loss=4.211, pp=67.39, acc=0.330645 [time per itr] 145.62ms [lr] 0.00099
0/10200 [train] loss=3.863 [val] loss=4.163, pp=64.26, acc=0.336316 [time per itr] 145.31ms [lr] 0.00099
0/10400 [train] loss=4.259 [val] loss=4.218, pp=67.88, acc=0.326632 [time per itr] 145.03ms [lr] 0.00099
0/10600 [train] loss=4.164 [val] loss=4.187, pp=65.81, acc=0.331474 [time per itr] 145.42ms [lr] 0.00099
0/10800 [train] loss=4.263 [val] loss=4.297, pp=73.46, acc=0.317027 [time per itr] 145.37ms [lr] 0.00099
0/11000 [train] loss=4.129 [val] loss=4.163, pp=64.25, acc=0.331276 [time per itr] 146.14ms [lr] 0.00099
0/11200 [train] loss=4.356 [val] loss=4.165, pp=64.41, acc=0.332662 [time per itr] 149.17ms [lr] 0.00099
0/11400 [train] loss=4.274 [val] loss=4.134, pp=62.44, acc=0.335330 [time per itr] 145.33ms [lr] 0.00099
0/11600 [train] loss=4.211 [val] loss=4.212, pp=67.49, acc=0.330162 [time per itr] 152.18ms [lr] 0.00099
0/11800 [train] loss=4.201 [val] loss=4.140, pp=62.83, acc=0.336756 [time per itr] 147.81ms [lr] 0.00099
0/12000 [train] loss=4.441 [val] loss=4.188, pp=65.87, acc=0.328850 [time per itr] 148.69ms [lr] 0.00099
0/12200 [train] loss=4.302 [val] loss=4.135, pp=62.46, acc=0.338656 [time per itr] 145.54ms [lr] 0.00099
0/12400 [train] loss=3.892 [val] loss=4.134, pp=62.41, acc=0.335368 [time per itr] 145.07ms [lr] 0.00099
0/12600 [train] loss=4.132 [val] loss=4.184, pp=65.61, acc=0.325055 [time per itr] 145.77ms [lr] 0.00099
0/12800 [train] loss=4.142 [val] loss=4.141, pp=62.84, acc=0.332995 [time per itr] 146.07ms [lr] 0.00099
0/13000 [train] loss=4.507 [val] loss=4.146, pp=63.16, acc=0.331540 [time per itr] 146.35ms [lr] 0.00098
0/13200 [train] loss=4.172 [val] loss=4.076, pp=58.90, acc=0.344182 [time per itr] 146.39ms [lr] 0.00098
0/13400 [train] loss=4.021 [val] loss=4.109, pp=60.90, acc=0.335678 [time per itr] 144.67ms [lr] 0.00098
0/13600 [train] loss=4.027 [val] loss=4.108, pp=60.82, acc=0.336896 [time per itr] 144.18ms [lr] 0.00098
0/13800 [train] loss=4.169 [val] loss=4.146, pp=63.19, acc=0.331390 [time per itr] 145.61ms [lr] 0.00098
0/14000 [train] loss=4.397 [val] loss=4.092, pp=59.88, acc=0.336276 [time per itr] 145.17ms [lr] 0.00098
0/14200 [train] loss=4.257 [val] loss=4.100, pp=60.36, acc=0.339559 [time per itr] 145.55ms [lr] 0.00098
0/14400 [train] loss=4.104 [val] loss=4.068, pp=58.46, acc=0.343793 [time per itr] 144.58ms [lr] 0.00098
0/14600 [train] loss=4.113 [val] loss=4.097, pp=60.18, acc=0.337690 [time per itr] 144.86ms [lr] 0.00098
0/14800 [train] loss=3.987 [val] loss=4.076, pp=58.91, acc=0.337710 [time per itr] 144.93ms [lr] 0.00098
0/15000 [train] loss=4.142 [val] loss=4.090, pp=59.71, acc=0.338015 [time per itr] 144.23ms [lr] 0.00098
0/15200 [train] loss=3.774 [val] loss=4.133, pp=62.39, acc=0.334145 [time per itr] 145.13ms [lr] 0.00097
0/15400 [train] loss=4.262 [val] loss=4.082, pp=59.28, acc=0.338661 [time per itr] 144.61ms [lr] 0.00097
0/15600 [train] loss=4.380 [val] loss=4.074, pp=58.79, acc=0.339287 [time per itr] 144.61ms [lr] 0.00097
0/15800 [train] loss=3.823 [val] loss=4.055, pp=57.69, acc=0.342616 [time per itr] 145.20ms [lr] 0.00097
0/16000 [train] loss=3.868 [val] loss=4.011, pp=55.19, acc=0.349444 [time per itr] 144.81ms [lr] 0.00097
0/16200 [train] loss=4.206 [val] loss=4.077, pp=58.99, acc=0.340286 [time per itr] 144.62ms [lr] 0.00097
0/16400 [train] loss=4.305 [val] loss=4.114, pp=61.22, acc=0.336678 [time per itr] 145.59ms [lr] 0.00097
0/16600 [train] loss=3.670 [val] loss=4.078, pp=59.03, acc=0.338608 [time per itr] 145.86ms [lr] 0.00097
0/16800 [train] loss=4.084 [val] loss=4.074, pp=58.77, acc=0.341077 [time per itr] 145.55ms [lr] 0.00097
0/17000 [train] loss=4.083 [val] loss=4.041, pp=56.87, acc=0.342557 [time per itr] 143.79ms [lr] 0.00097
0/17200 [train] loss=3.916 [val] loss=4.013, pp=55.30, acc=0.348129 [time per itr] 144.80ms [lr] 0.00096
0/17400 [train] loss=3.998 [val] loss=4.059, pp=57.93, acc=0.338542 [time per itr] 145.35ms [lr] 0.00096
0/17600 [train] loss=4.170 [val] loss=4.057, pp=57.83, acc=0.344220 [time per itr] 145.16ms [lr] 0.00096
0/17800 [train] loss=4.206 [val] loss=4.063, pp=58.14, acc=0.343030 [time per itr] 148.60ms [lr] 0.00096
0/18000 [train] loss=4.084 [val] loss=4.084, pp=59.37, acc=0.338356 [time per itr] 151.17ms [lr] 0.00096
0/18200 [train] loss=3.582 [val] loss=3.988, pp=53.95, acc=0.351117 [time per itr] 144.45ms [lr] 0.00096
0/18400 [train] loss=4.284 [val] loss=4.003, pp=54.74, acc=0.346217 [time per itr] 145.43ms [lr] 0.00096
0/18600 [train] loss=4.069 [val] loss=4.046, pp=57.20, acc=0.343979 [time per itr] 146.89ms [lr] 0.00096
0/18800 [train] loss=3.867 [val] loss=4.034, pp=56.47, acc=0.343437 [time per itr] 143.91ms [lr] 0.00095
0/19000 [train] loss=3.996 [val] loss=4.018, pp=55.57, acc=0.347730 [time per itr] 144.22ms [lr] 0.00095
0/19200 [train] loss=3.909 [val] loss=3.968, pp=52.89, acc=0.351064 [time per itr] 145.77ms [lr] 0.00095
0/19400 [train] loss=3.879 [val] loss=4.013, pp=55.29, acc=0.346352 [time per itr] 144.32ms [lr] 0.00095
0/19600 [train] loss=3.844 [val] loss=4.063, pp=58.17, acc=0.338338 [time per itr] 155.14ms [lr] 0.00095
0/19800 [train] loss=4.143 [val] loss=3.959, pp=52.43, acc=0.355265 [time per itr] 143.91ms [lr] 0.00095
0/20000 [train] loss=4.013 [val] loss=4.024, pp=55.94, acc=0.344149 [time per itr] 143.83ms [lr] 0.00095
0/20200 [train] loss=3.794 [val] loss=3.983, pp=53.67, acc=0.352102 [time per itr] 144.18ms [lr] 0.00094
0/20400 [train] loss=4.026 [val] loss=3.956, pp=52.24, acc=0.353462 [time per itr] 143.63ms [lr] 0.00094
0/20600 [train] loss=4.004 [val] loss=3.965, pp=52.72, acc=0.351517 [time per itr] 145.32ms [lr] 0.00094
0/20800 [train] loss=3.900 [val] loss=4.017, pp=55.51, acc=0.342878 [time per itr] 143.85ms [lr] 0.00094
0/21000 [train] loss=3.682 [val] loss=3.970, pp=52.98, acc=0.354108 [time per itr] 144.63ms [lr] 0.00094
0/21200 [train] loss=3.909 [val] loss=3.954, pp=52.13, acc=0.353038 [time per itr] 144.81ms [lr] 0.00094
0/21400 [train] loss=3.908 [val] loss=3.994, pp=54.27, acc=0.347959 [time per itr] 144.27ms [lr] 0.00094
0/21600 [train] loss=3.953 [val] loss=4.011, pp=55.19, acc=0.346802 [time per itr] 143.86ms [lr] 0.00093
0/21800 [train] loss=3.590 [val] loss=3.992, pp=54.15, acc=0.346357 [time per itr] 143.91ms [lr] 0.00093
0/22000 [train] loss=3.881 [val] loss=3.983, pp=53.66, acc=0.350777 [time per itr] 145.36ms [lr] 0.00093
0/22200 [train] loss=3.887 [val] loss=3.934, pp=51.13, acc=0.355398 [time per itr] 144.99ms [lr] 0.00093
0/22400 [train] loss=3.895 [val] loss=4.000, pp=54.61, acc=0.341886 [time per itr] 148.27ms [lr] 0.00093
0/22600 [train] loss=4.098 [val] loss=4.028, pp=56.13, acc=0.343272 [time per itr] 144.42ms [lr] 0.00093
0/22800 [train] loss=4.018 [val] loss=3.962, pp=52.59, acc=0.353813 [time per itr] 144.14ms [lr] 0.00092
0/23000 [train] loss=4.290 [val] loss=3.928, pp=50.80, acc=0.357994 [time per itr] 144.10ms [lr] 0.00092
0/23200 [train] loss=3.751 [val] loss=3.968, pp=52.87, acc=0.353772 [time per itr] 143.81ms [lr] 0.00092
0/23400 [train] loss=4.107 [val] loss=4.051, pp=57.45, acc=0.340520 [time per itr] 144.77ms [lr] 0.00092
0/23600 [train] loss=4.158 [val] loss=3.928, pp=50.80, acc=0.356534 [time per itr] 144.88ms [lr] 0.00092
0/23800 [train] loss=3.883 [val] loss=3.959, pp=52.42, acc=0.349861 [time per itr] 143.44ms [lr] 0.00092
0/24000 [train] loss=3.907 [val] loss=3.978, pp=53.40, acc=0.350726 [time per itr] 143.47ms [lr] 0.00091
0/24200 [train] loss=3.701 [val] loss=3.940, pp=51.43, acc=0.354858 [time per itr] 144.26ms [lr] 0.00091
0/24400 [train] loss=4.087 [val] loss=3.925, pp=50.64, acc=0.360423 [time per itr] 144.89ms [lr] 0.00091
0/24600 [train] loss=4.028 [val] loss=3.901, pp=49.46, acc=0.359828 [time per itr] 144.87ms [lr] 0.00091
0/24800 [train] loss=3.843 [val] loss=3.902, pp=49.48, acc=0.359439 [time per itr] 144.61ms [lr] 0.00091
0/25000 [train] loss=4.160 [val] loss=3.953, pp=52.07, acc=0.352051 [time per itr] 144.13ms [lr] 0.00091
0/25200 [train] loss=3.872 [val] loss=3.938, pp=51.33, acc=0.355044 [time per itr] 143.99ms [lr] 0.00090
0/25400 [train] loss=3.972 [val] loss=3.979, pp=53.44, acc=0.345983 [time per itr] 144.72ms [lr] 0.00090
0/25600 [train] loss=3.739 [val] loss=3.915, pp=50.14, acc=0.355288 [time per itr] 148.38ms [lr] 0.00090
0/25800 [train] loss=4.158 [val] loss=3.953, pp=52.11, acc=0.354548 [time per itr] 151.32ms [lr] 0.00090
0/26000 [train] loss=3.697 [val] loss=3.886, pp=48.70, acc=0.361720 [time per itr] 147.56ms [lr] 0.00090
0/26200 [train] loss=4.129 [val] loss=3.871, pp=48.01, acc=0.361638 [time per itr] 151.42ms [lr] 0.00089
0/26400 [train] loss=3.968 [val] loss=3.920, pp=50.42, acc=0.357091 [time per itr] 145.06ms [lr] 0.00089
0/26600 [train] loss=3.962 [val] loss=3.991, pp=54.09, acc=0.351082 [time per itr] 157.03ms [lr] 0.00089
0/26800 [train] loss=3.944 [val] loss=3.890, pp=48.90, acc=0.360115 [time per itr] 143.73ms [lr] 0.00089
0/27000 [train] loss=3.976 [val] loss=3.949, pp=51.91, acc=0.353333 [time per itr] 143.55ms [lr] 0.00089
0/27200 [train] loss=4.088 [val] loss=3.887, pp=48.77, acc=0.358803 [time per itr] 143.52ms [lr] 0.00088
0/27400 [train] loss=3.992 [val] loss=3.905, pp=49.65, acc=0.357610 [time per itr] 150.28ms [lr] 0.00088
0/27600 [train] loss=3.993 [val] loss=3.947, pp=51.79, acc=0.350314 [time per itr] 155.40ms [lr] 0.00088
0/27800 [train] loss=3.864 [val] loss=3.910, pp=49.92, acc=0.354238 [time per itr] 148.52ms [lr] 0.00088
0/28000 [train] loss=3.948 [val] loss=3.939, pp=51.37, acc=0.354312 [time per itr] 145.63ms [lr] 0.00088
0/28200 [train] loss=3.783 [val] loss=3.944, pp=51.64, acc=0.351568 [time per itr] 144.27ms [lr] 0.00087
0/28400 [train] loss=4.041 [val] loss=3.901, pp=49.47, acc=0.356598 [time per itr] 145.32ms [lr] 0.00087
0/28600 [train] loss=4.045 [val] loss=3.867, pp=47.78, acc=0.361287 [time per itr] 144.89ms [lr] 0.00087
0/28800 [train] loss=4.083 [val] loss=3.907, pp=49.75, acc=0.353271 [time per itr] 144.42ms [lr] 0.00087
0/29000 [train] loss=3.744 [val] loss=3.902, pp=49.52, acc=0.358187 [time per itr] 145.03ms [lr] 0.00087
0/29200 [train] loss=4.059 [val] loss=3.877, pp=48.26, acc=0.359990 [time per itr] 143.73ms [lr] 0.00086
0/29400 [train] loss=4.065 [val] loss=3.947, pp=51.76, acc=0.354568 [time per itr] 144.47ms [lr] 0.00086
0/29600 [train] loss=4.021 [val] loss=3.873, pp=48.07, acc=0.361376 [time per itr] 143.46ms [lr] 0.00086
0/29800 [train] loss=3.981 [val] loss=3.864, pp=47.68, acc=0.360229 [time per itr] 143.22ms [lr] 0.00086
0/30000 [train] loss=4.078 [val] loss=3.860, pp=47.48, acc=0.361491 [time per itr] 144.11ms [lr] 0.00085
0/30200 [train] loss=3.740 [val] loss=3.922, pp=50.51, acc=0.355082 [time per itr] 144.59ms [lr] 0.00085
0/30400 [train] loss=4.092 [val] loss=3.891, pp=48.95, acc=0.362350 [time per itr] 145.60ms [lr] 0.00085
0/30600 [train] loss=3.779 [val] loss=3.920, pp=50.39, acc=0.355520 [time per itr] 144.47ms [lr] 0.00085
0/30800 [train] loss=3.995 [val] loss=3.921, pp=50.45, acc=0.355418 [time per itr] 144.09ms [lr] 0.00085
0/31000 [train] loss=4.046 [val] loss=3.894, pp=49.12, acc=0.356280 [time per itr] 144.40ms [lr] 0.00084
0/31200 [train] loss=3.937 [val] loss=3.945, pp=51.67, acc=0.350904 [time per itr] 144.37ms [lr] 0.00084
0/31400 [train] loss=4.062 [val] loss=3.856, pp=47.28, acc=0.363876 [time per itr] 143.89ms [lr] 0.00084
0/31600 [train] loss=4.162 [val] loss=3.847, pp=46.84, acc=0.369273 [time per itr] 144.02ms [lr] 0.00084
0/31800 [train] loss=3.522 [val] loss=3.950, pp=51.92, acc=0.350756 [time per itr] 144.96ms [lr] 0.00083
0/32000 [train] loss=3.939 [val] loss=3.899, pp=49.35, acc=0.360936 [time per itr] 144.34ms [lr] 0.00083
0/32200 [train] loss=3.878 [val] loss=3.885, pp=48.67, acc=0.359103 [time per itr] 144.30ms [lr] 0.00083
0/32400 [train] loss=3.568 [val] loss=3.887, pp=48.76, acc=0.359146 [time per itr] 143.59ms [lr] 0.00083
0/32600 [train] loss=3.965 [val] loss=3.861, pp=47.52, acc=0.365072 [time per itr] 143.71ms [lr] 0.00083
0/32800 [train] loss=3.994 [val] loss=3.913, pp=50.03, acc=0.357519 [time per itr] 143.81ms [lr] 0.00082
0/33000 [train] loss=3.818 [val] loss=3.932, pp=51.03, acc=0.349948 [time per itr] 145.03ms [lr] 0.00082
0/33200 [train] loss=3.837 [val] loss=3.788, pp=44.18, acc=0.373838 [time per itr] 145.21ms [lr] 0.00082
0/33400 [train] loss=3.705 [val] loss=3.883, pp=48.57, acc=0.358602 [time per itr] 144.05ms [lr] 0.00082
0/33600 [train] loss=3.994 [val] loss=3.851, pp=47.05, acc=0.362668 [time per itr] 144.16ms [lr] 0.00081
0/33800 [train] loss=3.955 [val] loss=3.872, pp=48.04, acc=0.359884 [time per itr] 144.32ms [lr] 0.00081
0/34000 [train] loss=3.609 [val] loss=3.867, pp=47.80, acc=0.361753 [time per itr] 149.46ms [lr] 0.00081
0/34200 [train] loss=3.694 [val] loss=3.948, pp=51.82, acc=0.349139 [time per itr] 147.59ms [lr] 0.00081
0/34400 [train] loss=3.855 [val] loss=3.879, pp=48.36, acc=0.361572 [time per itr] 148.18ms [lr] 0.00080
0/34600 [train] loss=3.561 [val] loss=3.849, pp=46.96, acc=0.364212 [time per itr] 145.17ms [lr] 0.00080
0/34800 [train] loss=3.864 [val] loss=3.931, pp=50.97, acc=0.350769 [time per itr] 144.08ms [lr] 0.00080
0/35000 [train] loss=3.941 [val] loss=3.861, pp=47.49, acc=0.363884 [time per itr] 144.91ms [lr] 0.00080
0/35200 [train] loss=3.938 [val] loss=3.899, pp=49.33, acc=0.354121 [time per itr] 143.97ms [lr] 0.00079
0/35400 [train] loss=3.607 [val] loss=3.871, pp=47.97, acc=0.361280 [time per itr] 143.95ms [lr] 0.00079
0/35600 [train] loss=4.017 [val] loss=3.887, pp=48.78, acc=0.355471 [time per itr] 145.43ms [lr] 0.00079
0/35800 [train] loss=4.078 [val] loss=3.872, pp=48.04, acc=0.359495 [time per itr] 144.86ms [lr] 0.00079
0/36000 [train] loss=3.815 [val] loss=3.834, pp=46.25, acc=0.367475 [time per itr] 146.05ms [lr] 0.00078
0/36200 [train] loss=4.055 [val] loss=3.854, pp=47.19, acc=0.362765 [time per itr] 145.42ms [lr] 0.00078
0/36400 [train] loss=3.715 [val] loss=3.966, pp=52.80, acc=0.351105 [time per itr] 144.54ms [lr] 0.00078
0/36600 [train] loss=3.862 [val] loss=3.853, pp=47.13, acc=0.361186 [time per itr] 144.42ms [lr] 0.00078
0/36800 [train] loss=3.935 [val] loss=3.883, pp=48.56, acc=0.358917 [time per itr] 143.55ms [lr] 0.00077
0/37000 [train] loss=4.090 [val] loss=3.942, pp=51.54, acc=0.350728 [time per itr] 144.18ms [lr] 0.00077
0/37200 [train] loss=4.037 [val] loss=3.851, pp=47.03, acc=0.359566 [time per itr] 154.08ms [lr] 0.00077
0/37400 [train] loss=3.503 [val] loss=3.862, pp=47.58, acc=0.360641 [time per itr] 148.98ms [lr] 0.00077
0/37600 [train] loss=4.180 [val] loss=3.891, pp=48.97, acc=0.356036 [time per itr] 144.98ms [lr] 0.00076
0/37800 [train] loss=3.714 [val] loss=3.856, pp=47.27, acc=0.364675 [time per itr] 146.38ms [lr] 0.00076
0/38000 [train] loss=3.658 [val] loss=3.848, pp=46.88, acc=0.365636 [time per itr] 144.71ms [lr] 0.00076
0/38200 [train] loss=3.679 [val] loss=3.843, pp=46.69, acc=0.362785 [time per itr] 144.38ms [lr] 0.00075
0/38400 [train] loss=3.819 [val] loss=3.876, pp=48.22, acc=0.356936 [time per itr] 144.00ms [lr] 0.00075
0/38600 [train] loss=4.015 [val] loss=3.801, pp=44.75, acc=0.369217 [time per itr] 143.91ms [lr] 0.00075
0/38800 [train] loss=3.967 [val] loss=3.808, pp=45.04, acc=0.373100 [time per itr] 144.25ms [lr] 0.00075
0/39000 [train] loss=4.014 [val] loss=3.881, pp=48.46, acc=0.359662 [time per itr] 144.29ms [lr] 0.00074
0/39200 [train] loss=3.843 [val] loss=3.860, pp=47.45, acc=0.363080 [time per itr] 143.33ms [lr] 0.00074
0/39400 [train] loss=3.818 [val] loss=3.782, pp=43.89, acc=0.370196 [time per itr] 143.66ms [lr] 0.00074
0/39600 [train] loss=3.970 [val] loss=3.847, pp=46.84, acc=0.363429 [time per itr] 157.85ms [lr] 0.00074
0/39800 [train] loss=3.798 [val] loss=3.827, pp=45.93, acc=0.367025 [time per itr] 168.25ms [lr] 0.00073
0/40000 [train] loss=4.053 [val] loss=3.826, pp=45.88, acc=0.365489 [time per itr] 144.44ms [lr] 0.00073
0/40200 [train] loss=4.047 [val] loss=3.840, pp=46.52, acc=0.364736 [time per itr] 284.54ms [lr] 0.00073
0/40400 [train] loss=3.540 [val] loss=3.857, pp=47.33, acc=0.360603 [time per itr] 285.18ms [lr] 0.00073
0/40600 [train] loss=3.805 [val] loss=3.815, pp=45.38, acc=0.365672 [time per itr] 285.50ms [lr] 0.00072
0/40800 [train] loss=3.868 [val] loss=3.867, pp=47.81, acc=0.356990 [time per itr] 285.32ms [lr] 0.00072
0/41000 [train] loss=3.665 [val] loss=3.811, pp=45.17, acc=0.367851 [time per itr] 286.48ms [lr] 0.00072
0/41200 [train] loss=3.655 [val] loss=3.798, pp=44.60, acc=0.369731 [time per itr] 286.49ms [lr] 0.00071
0/41400 [train] loss=4.012 [val] loss=3.791, pp=44.28, acc=0.370763 [time per itr] 194.29ms [lr] 0.00071
0/41600 [train] loss=3.605 [val] loss=3.835, pp=46.28, acc=0.365049 [time per itr] 142.81ms [lr] 0.00071
0/41800 [train] loss=3.944 [val] loss=3.808, pp=45.06, acc=0.366994 [time per itr] 142.68ms [lr] 0.00071
0/42000 [train] loss=3.943 [val] loss=3.809, pp=45.11, acc=0.367215 [time per itr] 182.57ms [lr] 0.00070
0/42200 [train] loss=3.545 [val] loss=3.802, pp=44.77, acc=0.368342 [time per itr] 308.27ms [lr] 0.00070
0/42400 [train] loss=3.865 [val] loss=3.802, pp=44.78, acc=0.367083 [time per itr] 307.36ms [lr] 0.00070
0/42600 [train] loss=3.999 [val] loss=3.867, pp=47.81, acc=0.359767 [time per itr] 309.75ms [lr] 0.00069
0/42800 [train] loss=3.869 [val] loss=3.844, pp=46.71, acc=0.365033 [time per itr] 311.24ms [lr] 0.00069
0/43000 [train] loss=3.749 [val] loss=3.840, pp=46.51, acc=0.362378 [time per itr] 309.93ms [lr] 0.00069
0/43200 [train] loss=3.523 [val] loss=3.849, pp=46.92, acc=0.360031 [time per itr] 312.15ms [lr] 0.00069
0/43400 [train] loss=4.142 [val] loss=3.887, pp=48.79, acc=0.356527 [time per itr] 311.34ms [lr] 0.00068
0/43600 [train] loss=3.679 [val] loss=3.840, pp=46.51, acc=0.361692 [time per itr] 310.63ms [lr] 0.00068
0/43800 [train] loss=3.704 [val] loss=3.837, pp=46.37, acc=0.361677 [time per itr] 314.43ms [lr] 0.00068
0/44000 [train] loss=4.121 [val] loss=3.789, pp=44.22, acc=0.368706 [time per itr] 304.89ms [lr] 0.00067
0/44200 [train] loss=3.764 [val] loss=3.707, pp=40.74, acc=0.382238 [time per itr] 143.38ms [lr] 0.00067
0/44400 [train] loss=3.588 [val] loss=3.798, pp=44.62, acc=0.367060 [time per itr] 146.84ms [lr] 0.00067
0/44600 [train] loss=3.766 [val] loss=3.770, pp=43.39, acc=0.369420 [time per itr] 144.55ms [lr] 0.00067
0/44800 [train] loss=3.920 [val] loss=3.886, pp=48.70, acc=0.359062 [time per itr] 143.94ms [lr] 0.00066
0/45000 [train] loss=3.941 [val] loss=3.817, pp=45.46, acc=0.364957 [time per itr] 287.61ms [lr] 0.00066
0/45200 [train] loss=3.919 [val] loss=3.790, pp=44.28, acc=0.368095 [time per itr] 285.21ms [lr] 0.00066
0/45400 [train] loss=3.632 [val] loss=3.802, pp=44.78, acc=0.366481 [time per itr] 285.65ms [lr] 0.00065
0/45600 [train] loss=3.814 [val] loss=3.794, pp=44.45, acc=0.367312 [time per itr] 290.24ms [lr] 0.00065
0/45800 [train] loss=3.977 [val] loss=3.787, pp=44.14, acc=0.370059 [time per itr] 216.93ms [lr] 0.00065
0/46000 [train] loss=3.850 [val] loss=3.780, pp=43.81, acc=0.369715 [time per itr] 151.95ms [lr] 0.00065
0/46200 [train] loss=3.716 [val] loss=3.825, pp=45.86, acc=0.365875 [time per itr] 142.87ms [lr] 0.00064
0/46400 [train] loss=3.588 [val] loss=3.867, pp=47.81, acc=0.360667 [time per itr] 142.86ms [lr] 0.00064
0/46600 [train] loss=3.665 [val] loss=3.762, pp=43.05, acc=0.372597 [time per itr] 285.32ms [lr] 0.00064
0/46800 [train] loss=3.642 [val] loss=3.771, pp=43.43, acc=0.372660 [time per itr] 307.46ms [lr] 0.00063
0/47000 [train] loss=3.856 [val] loss=3.857, pp=47.31, acc=0.357681 [time per itr] 309.46ms [lr] 0.00063
0/47200 [train] loss=3.896 [val] loss=3.775, pp=43.60, acc=0.371854 [time per itr] 312.37ms [lr] 0.00063
0/47400 [train] loss=3.956 [val] loss=3.874, pp=48.12, acc=0.356946 [time per itr] 309.84ms [lr] 0.00063
0/47600 [train] loss=3.776 [val] loss=3.775, pp=43.60, acc=0.369952 [time per itr] 312.29ms [lr] 0.00062
0/47800 [train] loss=3.974 [val] loss=3.782, pp=43.92, acc=0.371437 [time per itr] 311.40ms [lr] 0.00062
0/48000 [train] loss=3.779 [val] loss=3.843, pp=46.64, acc=0.360374 [time per itr] 312.33ms [lr] 0.00062
0/48200 [train] loss=3.761 [val] loss=3.800, pp=44.69, acc=0.368235 [time per itr] 210.13ms [lr] 0.00061
0/48400 [train] loss=3.934 [val] loss=3.689, pp=40.02, acc=0.380529 [time per itr] 143.67ms [lr] 0.00061
0/48600 [train] loss=3.749 [val] loss=3.773, pp=43.52, acc=0.370926 [time per itr] 145.07ms [lr] 0.00061
0/48800 [train] loss=3.704 [val] loss=3.771, pp=43.41, acc=0.373047 [time per itr] 191.96ms [lr] 0.00060
0/49000 [train] loss=3.930 [val] loss=3.804, pp=44.89, acc=0.367429 [time per itr] 309.05ms [lr] 0.00060
0/49200 [train] loss=3.522 [val] loss=3.753, pp=42.66, acc=0.374013 [time per itr] 307.88ms [lr] 0.00060
0/49400 [train] loss=3.824 [val] loss=3.801, pp=44.75, acc=0.369016 [time per itr] 310.77ms [lr] 0.00060
0/49600 [train] loss=3.802 [val] loss=3.875, pp=48.18, acc=0.353320 [time per itr] 255.65ms [lr] 0.00059
0/49800 [train] loss=3.510 [val] loss=3.871, pp=47.97, acc=0.358246 [time per itr] 150.96ms [lr] 0.00059
0/50000 [train] loss=3.595 [val] loss=3.802, pp=44.78, acc=0.365237 [time per itr] 148.40ms [lr] 0.00059
0/50200 [train] loss=3.389 [val] loss=3.743, pp=42.21, acc=0.372391 [time per itr] 154.64ms [lr] 0.00058
0/50400 [train] loss=3.928 [val] loss=3.704, pp=40.63, acc=0.381175 [time per itr] 144.12ms [lr] 0.00058
0/50600 [train] loss=3.788 [val] loss=3.740, pp=42.09, acc=0.375089 [time per itr] 144.31ms [lr] 0.00058
0/50800 [train] loss=3.654 [val] loss=3.867, pp=47.78, acc=0.357742 [time per itr] 144.26ms [lr] 0.00058
0/51000 [train] loss=3.686 [val] loss=3.772, pp=43.46, acc=0.369303 [time per itr] 145.30ms [lr] 0.00057
0/51200 [train] loss=3.573 [val] loss=3.807, pp=45.02, acc=0.364822 [time per itr] 146.35ms [lr] 0.00057
0/51400 [train] loss=3.589 [val] loss=3.763, pp=43.06, acc=0.369965 [time per itr] 151.58ms [lr] 0.00057
0/51600 [train] loss=3.872 [val] loss=3.777, pp=43.68, acc=0.367076 [time per itr] 144.33ms [lr] 0.00056
0/51800 [train] loss=3.468 [val] loss=3.770, pp=43.38, acc=0.370150 [time per itr] 144.18ms [lr] 0.00056
0/52000 [train] loss=3.576 [val] loss=3.709, pp=40.82, acc=0.378260 [time per itr] 143.77ms [lr] 0.00056
0/52200 [train] loss=3.640 [val] loss=3.772, pp=43.45, acc=0.371045 [time per itr] 144.21ms [lr] 0.00055
0/52400 [train] loss=3.839 [val] loss=3.765, pp=43.17, acc=0.371078 [time per itr] 144.29ms [lr] 0.00055
0/52600 [train] loss=3.770 [val] loss=3.761, pp=42.97, acc=0.373873 [time per itr] 151.04ms [lr] 0.00055
0/52800 [train] loss=3.694 [val] loss=3.722, pp=41.34, acc=0.376381 [time per itr] 144.42ms [lr] 0.00055
0/53000 [train] loss=3.561 [val] loss=3.773, pp=43.52, acc=0.369781 [time per itr] 144.51ms [lr] 0.00054
0/53200 [train] loss=3.598 [val] loss=3.780, pp=43.81, acc=0.368624 [time per itr] 144.79ms [lr] 0.00054
0/53400 [train] loss=3.836 [val] loss=3.801, pp=44.77, acc=0.367933 [time per itr] 143.91ms [lr] 0.00054
0/53600 [train] loss=3.494 [val] loss=3.741, pp=42.14, acc=0.373416 [time per itr] 144.02ms [lr] 0.00053
0/53800 [train] loss=3.754 [val] loss=3.792, pp=44.34, acc=0.367500 [time per itr] 144.18ms [lr] 0.00053
0/54000 [train] loss=3.899 [val] loss=3.751, pp=42.56, acc=0.370626 [time per itr] 143.04ms [lr] 0.00053
0/54200 [train] loss=3.873 [val] loss=3.743, pp=42.22, acc=0.371966 [time per itr] 143.55ms [lr] 0.00052
0/54400 [train] loss=4.072 [val] loss=3.720, pp=41.25, acc=0.376086 [time per itr] 144.68ms [lr] 0.00052
0/54600 [train] loss=3.998 [val] loss=3.762, pp=43.05, acc=0.368688 [time per itr] 144.63ms [lr] 0.00052
0/54800 [train] loss=3.780 [val] loss=3.715, pp=41.05, acc=0.375015 [time per itr] 144.69ms [lr] 0.00052
0/55000 [train] loss=3.809 [val] loss=3.725, pp=41.47, acc=0.376175 [time per itr] 145.48ms [lr] 0.00051
0/55200 [train] loss=4.032 [val] loss=3.768, pp=43.27, acc=0.370265 [time per itr] 144.00ms [lr] 0.00051
0/55400 [train] loss=3.882 [val] loss=3.735, pp=41.90, acc=0.372737 [time per itr] 144.10ms [lr] 0.00051
0/55600 [train] loss=3.772 [val] loss=3.682, pp=39.72, acc=0.382556 [time per itr] 143.89ms [lr] 0.00050
0/55800 [train] loss=3.689 [val] loss=3.765, pp=43.17, acc=0.368787 [time per itr] 144.16ms [lr] 0.00050
0/56000 [train] loss=3.850 [val] loss=3.655, pp=38.68, acc=0.388423 [time per itr] 144.20ms [lr] 0.00050
0/56200 [train] loss=3.902 [val] loss=3.727, pp=41.56, acc=0.374504 [time per itr] 144.10ms [lr] 0.00050
0/56400 [train] loss=3.898 [val] loss=3.757, pp=42.83, acc=0.370127 [time per itr] 144.40ms [lr] 0.00049
0/56600 [train] loss=3.896 [val] loss=3.700, pp=40.45, acc=0.379224 [time per itr] 144.34ms [lr] 0.00049
0/56800 [train] loss=3.696 [val] loss=3.749, pp=42.49, acc=0.374023 [time per itr] 144.27ms [lr] 0.00049
0/57000 [train] loss=3.897 [val] loss=3.783, pp=43.93, acc=0.367348 [time per itr] 144.57ms [lr] 0.00048
0/57200 [train] loss=3.798 [val] loss=3.764, pp=43.11, acc=0.370814 [time per itr] 144.12ms [lr] 0.00048
0/57400 [train] loss=3.676 [val] loss=3.754, pp=42.70, acc=0.368790 [time per itr] 146.23ms [lr] 0.00048
0/57600 [train] loss=3.726 [val] loss=3.703, pp=40.56, acc=0.379028 [time per itr] 148.21ms [lr] 0.00047
0/57800 [train] loss=3.518 [val] loss=3.731, pp=41.73, acc=0.372993 [time per itr] 144.47ms [lr] 0.00047
0/58000 [train] loss=3.577 [val] loss=3.711, pp=40.91, acc=0.375280 [time per itr] 144.01ms [lr] 0.00047
0/58200 [train] loss=3.839 [val] loss=3.695, pp=40.25, acc=0.378568 [time per itr] 144.68ms [lr] 0.00047
0/58400 [train] loss=3.860 [val] loss=3.674, pp=39.39, acc=0.380971 [time per itr] 148.05ms [lr] 0.00046
0/58600 [train] loss=3.898 [val] loss=3.698, pp=40.39, acc=0.376907 [time per itr] 144.35ms [lr] 0.00046
0/58800 [train] loss=3.604 [val] loss=3.704, pp=40.59, acc=0.379690 [time per itr] 144.67ms [lr] 0.00046
0/59000 [train] loss=3.871 [val] loss=3.762, pp=43.02, acc=0.371429 [time per itr] 144.86ms [lr] 0.00045
0/59200 [train] loss=3.555 [val] loss=3.704, pp=40.59, acc=0.377988 [time per itr] 145.75ms [lr] 0.00045
0/59400 [train] loss=3.855 [val] loss=3.696, pp=40.28, acc=0.379041 [time per itr] 144.64ms [lr] 0.00045
0/59600 [train] loss=3.644 [val] loss=3.773, pp=43.50, acc=0.369410 [time per itr] 149.48ms [lr] 0.00045
0/59800 [train] loss=3.811 [val] loss=3.727, pp=41.57, acc=0.375824 [time per itr] 145.36ms [lr] 0.00044
0/60000 [train] loss=3.726 [val] loss=3.654, pp=38.61, acc=0.384631 [time per itr] 151.81ms [lr] 0.00044
0/60200 [train] loss=4.003 [val] loss=3.697, pp=40.32, acc=0.377319 [time per itr] 150.72ms [lr] 0.00044
0/60400 [train] loss=3.817 [val] loss=3.680, pp=39.64, acc=0.381106 [time per itr] 145.18ms [lr] 0.00043
0/60600 [train] loss=3.570 [val] loss=3.721, pp=41.30, acc=0.375796 [time per itr] 148.66ms [lr] 0.00043
0/60800 [train] loss=3.665 [val] loss=3.694, pp=40.20, acc=0.378977 [time per itr] 145.74ms [lr] 0.00043
0/61000 [train] loss=3.860 [val] loss=3.737, pp=41.95, acc=0.373492 [time per itr] 143.83ms [lr] 0.00043
0/61200 [train] loss=4.052 [val] loss=3.701, pp=40.50, acc=0.377139 [time per itr] 144.24ms [lr] 0.00042
0/61400 [train] loss=3.637 [val] loss=3.712, pp=40.94, acc=0.375397 [time per itr] 145.64ms [lr] 0.00042
0/61600 [train] loss=3.768 [val] loss=3.775, pp=43.58, acc=0.369993 [time per itr] 143.35ms [lr] 0.00042
0/61800 [train] loss=3.719 [val] loss=3.683, pp=39.78, acc=0.379720 [time per itr] 145.22ms [lr] 0.00041
0/62000 [train] loss=4.002 [val] loss=3.688, pp=39.95, acc=0.379250 [time per itr] 145.76ms [lr] 0.00041
0/62200 [train] loss=3.570 [val] loss=3.694, pp=40.20, acc=0.377660 [time per itr] 147.73ms [lr] 0.00041
0/62400 [train] loss=3.698 [val] loss=3.666, pp=39.08, acc=0.381376 [time per itr] 144.34ms [lr] 0.00041
0/62600 [train] loss=3.667 [val] loss=3.730, pp=41.68, acc=0.371058 [time per itr] 150.51ms [lr] 0.00040
0/62800 [train] loss=3.837 [val] loss=3.708, pp=40.79, acc=0.375679 [time per itr] 146.81ms [lr] 0.00040
0/63000 [train] loss=3.661 [val] loss=3.698, pp=40.36, acc=0.380028 [time per itr] 144.56ms [lr] 0.00040
0/63200 [train] loss=3.659 [val] loss=3.667, pp=39.12, acc=0.383476 [time per itr] 145.73ms [lr] 0.00039
0/63400 [train] loss=3.352 [val] loss=3.674, pp=39.42, acc=0.378128 [time per itr] 144.10ms [lr] 0.00039
0/63600 [train] loss=3.883 [val] loss=3.639, pp=38.06, acc=0.384768 [time per itr] 147.84ms [lr] 0.00039
0/63800 [train] loss=3.869 [val] loss=3.698, pp=40.36, acc=0.375242 [time per itr] 144.45ms [lr] 0.00039
0/64000 [train] loss=3.827 [val] loss=3.694, pp=40.22, acc=0.376900 [time per itr] 144.25ms [lr] 0.00038
0/64200 [train] loss=3.840 [val] loss=3.720, pp=41.26, acc=0.373716 [time per itr] 145.30ms [lr] 0.00038
0/64400 [train] loss=3.624 [val] loss=3.661, pp=38.90, acc=0.382589 [time per itr] 144.77ms [lr] 0.00038
0/64600 [train] loss=3.842 [val] loss=3.691, pp=40.07, acc=0.382029 [time per itr] 144.21ms [lr] 0.00037
0/64800 [train] loss=3.808 [val] loss=3.631, pp=37.75, acc=0.385284 [time per itr] 145.24ms [lr] 0.00037
0/65000 [train] loss=3.835 [val] loss=3.698, pp=40.35, acc=0.376086 [time per itr] 145.05ms [lr] 0.00037
0/65200 [train] loss=3.608 [val] loss=3.641, pp=38.13, acc=0.384394 [time per itr] 144.00ms [lr] 0.00037
0/65400 [train] loss=3.301 [val] loss=3.667, pp=39.15, acc=0.379949 [time per itr] 144.01ms [lr] 0.00036
0/65600 [train] loss=3.604 [val] loss=3.643, pp=38.22, acc=0.387225 [time per itr] 144.41ms [lr] 0.00036
0/65800 [train] loss=3.760 [val] loss=3.668, pp=39.17, acc=0.381884 [time per itr] 144.12ms [lr] 0.00036
0/66000 [train] loss=3.541 [val] loss=3.668, pp=39.18, acc=0.379387 [time per itr] 144.48ms [lr] 0.00036
0/66200 [train] loss=3.760 [val] loss=3.710, pp=40.86, acc=0.375516 [time per itr] 143.69ms [lr] 0.00035
0/66400 [train] loss=3.635 [val] loss=3.723, pp=41.37, acc=0.373599 [time per itr] 144.39ms [lr] 0.00035
0/66600 [train] loss=3.708 [val] loss=3.657, pp=38.73, acc=0.382645 [time per itr] 144.14ms [lr] 0.00035
0/66800 [train] loss=3.713 [val] loss=3.723, pp=41.38, acc=0.372019 [time per itr] 143.54ms [lr] 0.00035
0/67000 [train] loss=3.654 [val] loss=3.662, pp=38.95, acc=0.380918 [time per itr] 144.31ms [lr] 0.00034
0/67200 [train] loss=3.838 [val] loss=3.650, pp=38.46, acc=0.383311 [time per itr] 144.22ms [lr] 0.00034
0/67400 [train] loss=3.447 [val] loss=3.634, pp=37.88, acc=0.385846 [time per itr] 144.14ms [lr] 0.00034
0/67600 [train] loss=3.638 [val] loss=3.648, pp=38.38, acc=0.383481 [time per itr] 143.96ms [lr] 0.00033
0/67800 [train] loss=3.430 [val] loss=3.605, pp=36.79, acc=0.389440 [time per itr] 148.33ms [lr] 0.00033
0/68000 [train] loss=3.976 [val] loss=3.663, pp=38.96, acc=0.382914 [time per itr] 150.23ms [lr] 0.00033
0/68200 [train] loss=3.529 [val] loss=3.701, pp=40.48, acc=0.377434 [time per itr] 145.06ms [lr] 0.00033
0/68400 [train] loss=3.466 [val] loss=3.692, pp=40.11, acc=0.376127 [time per itr] 144.53ms [lr] 0.00032
0/68600 [train] loss=3.258 [val] loss=3.648, pp=38.40, acc=0.383876 [time per itr] 143.88ms [lr] 0.00032
0/68800 [train] loss=3.578 [val] loss=3.625, pp=37.52, acc=0.384575 [time per itr] 144.11ms [lr] 0.00032
0/69000 [train] loss=3.621 [val] loss=3.628, pp=37.64, acc=0.385712 [time per itr] 143.78ms [lr] 0.00032
0/69200 [train] loss=3.553 [val] loss=3.624, pp=37.48, acc=0.388868 [time per itr] 145.64ms [lr] 0.00031
0/69400 [train] loss=3.659 [val] loss=3.637, pp=37.97, acc=0.385997 [time per itr] 148.23ms [lr] 0.00031
0/69600 [train] loss=3.604 [val] loss=3.591, pp=36.25, acc=0.389931 [time per itr] 144.03ms [lr] 0.00031
0/69800 [train] loss=3.658 [val] loss=3.603, pp=36.70, acc=0.388794 [time per itr] 146.17ms [lr] 0.00031
0/70000 [train] loss=3.437 [val] loss=3.633, pp=37.81, acc=0.383870 [time per itr] 148.53ms [lr] 0.00030
0/70200 [train] loss=3.613 [val] loss=3.610, pp=36.95, acc=0.386930 [time per itr] 150.79ms [lr] 0.00030
0/70400 [train] loss=3.704 [val] loss=3.626, pp=37.57, acc=0.386744 [time per itr] 149.34ms [lr] 0.00030
0/70600 [train] loss=3.570 [val] loss=3.654, pp=38.62, acc=0.383980 [time per itr] 144.26ms [lr] 0.00030
0/70800 [train] loss=3.785 [val] loss=3.641, pp=38.13, acc=0.382256 [time per itr] 144.70ms [lr] 0.00029
0/71000 [train] loss=3.706 [val] loss=3.641, pp=38.15, acc=0.382634 [time per itr] 146.71ms [lr] 0.00029
0/71200 [train] loss=3.522 [val] loss=3.672, pp=39.35, acc=0.378204 [time per itr] 143.92ms [lr] 0.00029
0/71400 [train] loss=3.710 [val] loss=3.642, pp=38.16, acc=0.381513 [time per itr] 148.72ms [lr] 0.00029
0/71600 [train] loss=3.579 [val] loss=3.657, pp=38.74, acc=0.382067 [time per itr] 146.97ms [lr] 0.00028
0/71800 [train] loss=3.764 [val] loss=3.632, pp=37.77, acc=0.386772 [time per itr] 153.73ms [lr] 0.00028
0/72000 [train] loss=3.423 [val] loss=3.650, pp=38.46, acc=0.382698 [time per itr] 145.31ms [lr] 0.00028
0/72200 [train] loss=3.679 [val] loss=3.590, pp=36.24, acc=0.390480 [time per itr] 147.42ms [lr] 0.00028
0/72400 [train] loss=3.502 [val] loss=3.648, pp=38.39, acc=0.382113 [time per itr] 150.02ms [lr] 0.00027
0/72600 [train] loss=3.655 [val] loss=3.604, pp=36.73, acc=0.386726 [time per itr] 145.59ms [lr] 0.00027
0/72800 [train] loss=3.607 [val] loss=3.654, pp=38.64, acc=0.379639 [time per itr] 144.46ms [lr] 0.00027
0/73000 [train] loss=3.817 [val] loss=3.600, pp=36.60, acc=0.389837 [time per itr] 144.00ms [lr] 0.00027
0/73200 [train] loss=3.908 [val] loss=3.642, pp=38.16, acc=0.382403 [time per itr] 143.70ms [lr] 0.00027
0/73400 [train] loss=3.679 [val] loss=3.646, pp=38.30, acc=0.378494 [time per itr] 143.71ms [lr] 0.00026
0/73600 [train] loss=3.540 [val] loss=3.613, pp=37.10, acc=0.388769 [time per itr] 144.51ms [lr] 0.00026
0/73800 [train] loss=3.745 [val] loss=3.556, pp=35.01, acc=0.392820 [time per itr] 144.84ms [lr] 0.00026
0/74000 [train] loss=3.908 [val] loss=3.669, pp=39.19, acc=0.378654 [time per itr] 144.54ms [lr] 0.00026
0/74200 [train] loss=3.526 [val] loss=3.606, pp=36.81, acc=0.388934 [time per itr] 144.54ms [lr] 0.00025
0/74400 [train] loss=3.343 [val] loss=3.593, pp=36.35, acc=0.389315 [time per itr] 143.98ms [lr] 0.00025
0/74600 [train] loss=3.528 [val] loss=3.666, pp=39.09, acc=0.381111 [time per itr] 144.65ms [lr] 0.00025
0/74800 [train] loss=3.682 [val] loss=3.606, pp=36.83, acc=0.386401 [time per itr] 146.29ms [lr] 0.00025
0/75000 [train] loss=3.734 [val] loss=3.644, pp=38.26, acc=0.383469 [time per itr] 148.21ms [lr] 0.00025
0/75200 [train] loss=3.521 [val] loss=3.579, pp=35.84, acc=0.391617 [time per itr] 144.98ms [lr] 0.00024
0/75400 [train] loss=3.275 [val] loss=3.659, pp=38.82, acc=0.381371 [time per itr] 143.83ms [lr] 0.00024
0/75600 [train] loss=3.657 [val] loss=3.558, pp=35.08, acc=0.394061 [time per itr] 144.33ms [lr] 0.00024
0/75800 [train] loss=3.755 [val] loss=3.561, pp=35.19, acc=0.393687 [time per itr] 144.06ms [lr] 0.00024
0/76000 [train] loss=3.719 [val] loss=3.650, pp=38.49, acc=0.378064 [time per itr] 144.98ms [lr] 0.00023
0/76200 [train] loss=3.733 [val] loss=3.602, pp=36.66, acc=0.386416 [time per itr] 145.11ms [lr] 0.00023
0/76400 [train] loss=3.535 [val] loss=3.585, pp=36.06, acc=0.389834 [time per itr] 144.87ms [lr] 0.00023
0/76600 [train] loss=3.771 [val] loss=3.560, pp=35.15, acc=0.396289 [time per itr] 144.03ms [lr] 0.00023
0/76800 [train] loss=3.384 [val] loss=3.611, pp=37.00, acc=0.386650 [time per itr] 143.55ms [lr] 0.00023
0/77000 [train] loss=3.646 [val] loss=3.602, pp=36.66, acc=0.388512 [time per itr] 144.41ms [lr] 0.00022
0/77200 [train] loss=3.516 [val] loss=3.536, pp=34.32, acc=0.397654 [time per itr] 144.44ms [lr] 0.00022
0/77400 [train] loss=3.773 [val] loss=3.570, pp=35.51, acc=0.390259 [time per itr] 144.08ms [lr] 0.00022
0/77600 [train] loss=3.409 [val] loss=3.598, pp=36.54, acc=0.391014 [time per itr] 144.76ms [lr] 0.00022
0/77800 [train] loss=3.423 [val] loss=3.594, pp=36.39, acc=0.390124 [time per itr] 143.95ms [lr] 0.00022
0/78000 [train] loss=3.240 [val] loss=3.575, pp=35.70, acc=0.393016 [time per itr] 144.05ms [lr] 0.00021
0/78200 [train] loss=3.641 [val] loss=3.538, pp=34.41, acc=0.398504 [time per itr] 144.80ms [lr] 0.00021
0/78400 [train] loss=3.548 [val] loss=3.558, pp=35.09, acc=0.390752 [time per itr] 144.88ms [lr] 0.00021
0/78600 [train] loss=3.209 [val] loss=3.540, pp=34.48, acc=0.396352 [time per itr] 143.94ms [lr] 0.00021
0/78800 [train] loss=3.671 [val] loss=3.595, pp=36.43, acc=0.387428 [time per itr] 157.67ms [lr] 0.00021
0/79000 [train] loss=3.562 [val] loss=3.577, pp=35.77, acc=0.393155 [time per itr] 146.18ms [lr] 0.00020
0/79200 [train] loss=3.845 [val] loss=3.565, pp=35.34, acc=0.390836 [time per itr] 152.65ms [lr] 0.00020
0/79400 [train] loss=3.644 [val] loss=3.559, pp=35.11, acc=0.393021 [time per itr] 144.96ms [lr] 0.00020
0/79600 [train] loss=3.584 [val] loss=3.598, pp=36.53, acc=0.389674 [time per itr] 143.91ms [lr] 0.00020
0/79800 [train] loss=3.765 [val] loss=3.564, pp=35.30, acc=0.393725 [time per itr] 144.17ms [lr] 0.00020
0/80000 [train] loss=3.524 [val] loss=3.595, pp=36.40, acc=0.388341 [time per itr] 144.36ms [lr] 0.00019
0/80200 [train] loss=3.375 [val] loss=3.618, pp=37.28, acc=0.384832 [time per itr] 146.78ms [lr] 0.00019
0/80400 [train] loss=3.504 [val] loss=3.528, pp=34.06, acc=0.397316 [time per itr] 152.59ms [lr] 0.00019
0/80600 [train] loss=3.430 [val] loss=3.511, pp=33.48, acc=0.401746 [time per itr] 145.85ms [lr] 0.00019
0/80800 [train] loss=3.448 [val] loss=3.582, pp=35.95, acc=0.390661 [time per itr] 145.83ms [lr] 0.00019
0/81000 [train] loss=3.671 [val] loss=3.584, pp=36.02, acc=0.387909 [time per itr] 144.32ms [lr] 0.00019
0/81200 [train] loss=3.385 [val] loss=3.586, pp=36.10, acc=0.389064 [time per itr] 143.63ms [lr] 0.00018
0/81400 [train] loss=3.553 [val] loss=3.523, pp=33.89, acc=0.398376 [time per itr] 144.00ms [lr] 0.00018
0/81600 [train] loss=3.495 [val] loss=3.523, pp=33.90, acc=0.396622 [time per itr] 143.55ms [lr] 0.00018
0/81800 [train] loss=3.383 [val] loss=3.540, pp=34.47, acc=0.394257 [time per itr] 143.55ms [lr] 0.00018
0/82000 [train] loss=3.659 [val] loss=3.574, pp=35.67, acc=0.391299 [time per itr] 144.02ms [lr] 0.00018
0/82200 [train] loss=3.754 [val] loss=3.526, pp=33.99, acc=0.397898 [time per itr] 144.64ms [lr] 0.00018
0/82400 [train] loss=3.299 [val] loss=3.496, pp=32.98, acc=0.398992 [time per itr] 148.67ms [lr] 0.00017
0/82600 [train] loss=3.688 [val] loss=3.536, pp=34.34, acc=0.395521 [time per itr] 147.19ms [lr] 0.00017
0/82800 [train] loss=3.681 [val] loss=3.519, pp=33.74, acc=0.397385 [time per itr] 144.33ms [lr] 0.00017
0/83000 [train] loss=3.735 [val] loss=3.526, pp=33.98, acc=0.397079 [time per itr] 144.17ms [lr] 0.00017
0/83200 [train] loss=3.727 [val] loss=3.534, pp=34.26, acc=0.396108 [time per itr] 143.52ms [lr] 0.00017
0/83400 [train] loss=3.738 [val] loss=3.581, pp=35.91, acc=0.390409 [time per itr] 145.46ms [lr] 0.00017
0/83600 [train] loss=3.271 [val] loss=3.530, pp=34.11, acc=0.397504 [time per itr] 150.32ms [lr] 0.00016
0/83800 [train] loss=3.408 [val] loss=3.510, pp=33.46, acc=0.401151 [time per itr] 147.84ms [lr] 0.00016
0/84000 [train] loss=3.643 [val] loss=3.548, pp=34.75, acc=0.393069 [time per itr] 145.55ms [lr] 0.00016
0/84200 [train] loss=3.784 [val] loss=3.501, pp=33.13, acc=0.400424 [time per itr] 146.25ms [lr] 0.00016
0/84400 [train] loss=3.324 [val] loss=3.518, pp=33.72, acc=0.396403 [time per itr] 146.47ms [lr] 0.00016
0/84600 [train] loss=3.254 [val] loss=3.542, pp=34.55, acc=0.393842 [time per itr] 146.59ms [lr] 0.00016
0/84800 [train] loss=3.483 [val] loss=3.528, pp=34.04, acc=0.396416 [time per itr] 143.82ms [lr] 0.00016
0/85000 [train] loss=3.543 [val] loss=3.546, pp=34.67, acc=0.394859 [time per itr] 144.35ms [lr] 0.00015
0/85200 [train] loss=3.463 [val] loss=3.562, pp=35.24, acc=0.393842 [time per itr] 148.28ms [lr] 0.00015
0/85400 [train] loss=3.397 [val] loss=3.522, pp=33.85, acc=0.397687 [time per itr] 143.55ms [lr] 0.00015
0/85600 [train] loss=3.619 [val] loss=3.542, pp=34.55, acc=0.393005 [time per itr] 143.66ms [lr] 0.00015
0/85800 [train] loss=3.603 [val] loss=3.467, pp=32.04, acc=0.405815 [time per itr] 143.79ms [lr] 0.00015
0/86000 [train] loss=3.666 [val] loss=3.505, pp=33.26, acc=0.396551 [time per itr] 144.50ms [lr] 0.00015
0/86200 [train] loss=3.217 [val] loss=3.518, pp=33.72, acc=0.396044 [time per itr] 144.58ms [lr] 0.00015
0/86400 [train] loss=3.760 [val] loss=3.482, pp=32.51, acc=0.402016 [time per itr] 144.67ms [lr] 0.00014
0/86600 [train] loss=3.603 [val] loss=3.471, pp=32.16, acc=0.404035 [time per itr] 144.30ms [lr] 0.00014
0/86800 [train] loss=3.746 [val] loss=3.498, pp=33.05, acc=0.398727 [time per itr] 149.65ms [lr] 0.00014
0/87000 [train] loss=3.668 [val] loss=3.530, pp=34.14, acc=0.393041 [time per itr] 151.96ms [lr] 0.00014
0/87200 [train] loss=3.334 [val] loss=3.551, pp=34.84, acc=0.390818 [time per itr] 144.41ms [lr] 0.00014
0/87400 [train] loss=3.527 [val] loss=3.482, pp=32.51, acc=0.405078 [time per itr] 158.09ms [lr] 0.00014
0/87600 [train] loss=3.349 [val] loss=3.514, pp=33.60, acc=0.396047 [time per itr] 149.87ms [lr] 0.00014
0/87800 [train] loss=3.735 [val] loss=3.488, pp=32.72, acc=0.401255 [time per itr] 144.13ms [lr] 0.00014
0/88000 [train] loss=3.498 [val] loss=3.483, pp=32.56, acc=0.401792 [time per itr] 144.47ms [lr] 0.00013
0/88200 [train] loss=3.670 [val] loss=3.517, pp=33.67, acc=0.394501 [time per itr] 144.38ms [lr] 0.00013
0/88400 [train] loss=3.418 [val] loss=3.470, pp=32.12, acc=0.405329 [time per itr] 144.42ms [lr] 0.00013
0/88600 [train] loss=3.343 [val] loss=3.533, pp=34.23, acc=0.393636 [time per itr] 143.81ms [lr] 0.00013
0/88800 [train] loss=3.617 [val] loss=3.462, pp=31.89, acc=0.402509 [time per itr] 144.32ms [lr] 0.00013
0/89000 [train] loss=3.516 [val] loss=3.511, pp=33.49, acc=0.395940 [time per itr] 144.42ms [lr] 0.00013
0/89200 [train] loss=3.555 [val] loss=3.498, pp=33.03, acc=0.397598 [time per itr] 144.44ms [lr] 0.00013
0/89400 [train] loss=3.777 [val] loss=3.483, pp=32.57, acc=0.403605 [time per itr] 144.49ms [lr] 0.00013
0/89600 [train] loss=3.621 [val] loss=3.515, pp=33.63, acc=0.398616 [time per itr] 144.53ms [lr] 0.00013
0/89800 [train] loss=3.570 [val] loss=3.469, pp=32.10, acc=0.402969 [time per itr] 144.62ms [lr] 0.00013
0/90000 [train] loss=3.195 [val] loss=3.474, pp=32.25, acc=0.402161 [time per itr] 144.17ms [lr] 0.00012
0/90200 [train] loss=3.368 [val] loss=3.471, pp=32.18, acc=0.403557 [time per itr] 143.65ms [lr] 0.00012
0/90400 [train] loss=3.428 [val] loss=3.540, pp=34.48, acc=0.396662 [time per itr] 144.67ms [lr] 0.00012
0/90600 [train] loss=3.265 [val] loss=3.442, pp=31.26, acc=0.406873 [time per itr] 145.29ms [lr] 0.00012
0/90800 [train] loss=3.590 [val] loss=3.466, pp=32.01, acc=0.404793 [time per itr] 143.47ms [lr] 0.00012
0/91000 [train] loss=3.714 [val] loss=3.501, pp=33.14, acc=0.398539 [time per itr] 151.97ms [lr] 0.00012
0/91200 [train] loss=3.502 [val] loss=3.495, pp=32.97, acc=0.401179 [time per itr] 149.31ms [lr] 0.00012
0/91400 [train] loss=3.653 [val] loss=3.529, pp=34.09, acc=0.395192 [time per itr] 155.52ms [lr] 0.00012
0/91600 [train] loss=3.608 [val] loss=3.489, pp=32.76, acc=0.399689 [time per itr] 143.70ms [lr] 0.00012
0/91800 [train] loss=3.124 [val] loss=3.436, pp=31.06, acc=0.406868 [time per itr] 145.07ms [lr] 0.00012
0/92000 [train] loss=3.532 [val] loss=3.474, pp=32.28, acc=0.402908 [time per itr] 144.83ms [lr] 0.00012
0/92200 [train] loss=3.409 [val] loss=3.532, pp=34.21, acc=0.392563 [time per itr] 144.29ms [lr] 0.00011
0/92400 [train] loss=3.326 [val] loss=3.514, pp=33.60, acc=0.397682 [time per itr] 152.12ms [lr] 0.00011
0/92600 [train] loss=3.769 [val] loss=3.469, pp=32.12, acc=0.405017 [time per itr] 148.87ms [lr] 0.00011
0/92800 [train] loss=3.557 [val] loss=3.484, pp=32.58, acc=0.401006 [time per itr] 145.51ms [lr] 0.00011
0/93000 [train] loss=3.534 [val] loss=3.445, pp=31.35, acc=0.407183 [time per itr] 145.89ms [lr] 0.00011
0/93200 [train] loss=3.352 [val] loss=3.491, pp=32.83, acc=0.399813 [time per itr] 144.58ms [lr] 0.00011
0/93400 [train] loss=3.457 [val] loss=3.445, pp=31.35, acc=0.404696 [time per itr] 144.71ms [lr] 0.00011
0/93600 [train] loss=3.697 [val] loss=3.495, pp=32.94, acc=0.401431 [time per itr] 144.52ms [lr] 0.00011
0/93800 [train] loss=3.389 [val] loss=3.474, pp=32.27, acc=0.404035 [time per itr] 143.68ms [lr] 0.00011
0/94000 [train] loss=3.048 [val] loss=3.526, pp=34.00, acc=0.397425 [time per itr] 144.63ms [lr] 0.00011
0/94200 [train] loss=3.212 [val] loss=3.474, pp=32.27, acc=0.403013 [time per itr] 144.16ms [lr] 0.00011
0/94400 [train] loss=3.510 [val] loss=3.504, pp=33.24, acc=0.401192 [time per itr] 143.83ms [lr] 0.00011
0/94600 [train] loss=3.400 [val] loss=3.459, pp=31.79, acc=0.403804 [time per itr] 143.56ms [lr] 0.00011
0/94800 [train] loss=3.572 [val] loss=3.513, pp=33.56, acc=0.396601 [time per itr] 144.49ms [lr] 0.00011
0/95000 [train] loss=3.553 [val] loss=3.404, pp=30.08, acc=0.411339 [time per itr] 143.67ms [lr] 0.00011
0/95200 [train] loss=3.295 [val] loss=3.500, pp=33.11, acc=0.401718 [time per itr] 143.98ms [lr] 0.00011
0/95400 [train] loss=3.651 [val] loss=3.467, pp=32.04, acc=0.403005 [time per itr] 144.27ms [lr] 0.00011
0/95600 [train] loss=3.466 [val] loss=3.479, pp=32.42, acc=0.399549 [time per itr] 146.31ms [lr] 0.00010
0/95800 [train] loss=3.288 [val] loss=3.444, pp=31.30, acc=0.409045 [time per itr] 162.09ms [lr] 0.00010
0/96000 [train] loss=3.294 [val] loss=3.442, pp=31.26, acc=0.404648 [time per itr] 150.13ms [lr] 0.00010
0/96200 [train] loss=3.472 [val] loss=3.455, pp=31.65, acc=0.403842 [time per itr] 144.39ms [lr] 0.00010
0/96400 [train] loss=3.235 [val] loss=3.496, pp=32.99, acc=0.397606 [time per itr] 144.25ms [lr] 0.00010
0/96600 [train] loss=3.363 [val] loss=3.455, pp=31.66, acc=0.407590 [time per itr] 143.90ms [lr] 0.00010
0/96800 [train] loss=3.693 [val] loss=3.444, pp=31.31, acc=0.406174 [time per itr] 143.69ms [lr] 0.00010
0/97000 [train] loss=3.380 [val] loss=3.486, pp=32.65, acc=0.399068 [time per itr] 144.46ms [lr] 0.00010
0/97200 [train] loss=3.444 [val] loss=3.487, pp=32.70, acc=0.400721 [time per itr] 143.81ms [lr] 0.00010
0/97400 [train] loss=3.373 [val] loss=3.476, pp=32.34, acc=0.406151 [time per itr] 144.64ms [lr] 0.00010
0/97600 [train] loss=3.614 [val] loss=3.447, pp=31.39, acc=0.404928 [time per itr] 144.28ms [lr] 0.00010
0/97800 [train] loss=3.631 [val] loss=3.448, pp=31.44, acc=0.406741 [time per itr] 144.48ms [lr] 0.00010
0/98000 [train] loss=3.306 [val] loss=3.441, pp=31.21, acc=0.406596 [time per itr] 145.10ms [lr] 0.00010
0/98200 [train] loss=3.312 [val] loss=3.471, pp=32.18, acc=0.402812 [time per itr] 144.70ms [lr] 0.00010
0/98400 [train] loss=3.766 [val] loss=3.476, pp=32.33, acc=0.400380 [time per itr] 143.86ms [lr] 0.00010
0/98600 [train] loss=3.348 [val] loss=3.469, pp=32.10, acc=0.402906 [time per itr] 144.39ms [lr] 0.00010
0/98800 [train] loss=3.597 [val] loss=3.472, pp=32.20, acc=0.405045 [time per itr] 145.07ms [lr] 0.00010
0/99000 [train] loss=3.467 [val] loss=3.476, pp=32.34, acc=0.400635 [time per itr] 143.70ms [lr] 0.00010
0/99200 [train] loss=3.338 [val] loss=3.468, pp=32.08, acc=0.403023 [time per itr] 144.12ms [lr] 0.00010
0/99400 [train] loss=3.521 [val] loss=3.461, pp=31.85, acc=0.403229 [time per itr] 144.17ms [lr] 0.00010
0/99600 [train] loss=3.525 [val] loss=3.471, pp=32.16, acc=0.405024 [time per itr] 145.63ms [lr] 0.00010
0/99800 [train] loss=3.696 [val] loss=3.501, pp=33.15, acc=0.401105 [time per itr] 144.70ms [lr] 0.00010
0/100000 [train] loss=3.180 [val] loss=3.460, pp=31.82, acc=0.403921 [time per itr] 144.22ms [lr] 0.00010
saving checkpoint to ./exps/slimpajama/base/base_lr0.001_bs32x4_seqlen512/no_doge=True_run_id=20250915_222420_seed=0/20250915_222420/ckpt.pt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mbase_lr0.001_bs32x4_seqlen512/no_doge=True_run_id=20250915_222420_seed=0[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250915_222559-h9va4olf/logs[0m
