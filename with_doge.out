nohup: ignoring input
wandb: Currently logged in as: ruben-navasardyan4869 (ruben-navasardyan4869-epfl) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.4
wandb: Run data is saved locally in /mloscratch/homes/navasard/moe_doge/llm-baselines-moe/wandb/run-20250915_222529-noiou2md
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run base_lr0.001_bs32x4_seqlen512/run_id=20250915_222348_seed=0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ruben-navasardyan4869-epfl/token-mix-moe
wandb: üöÄ View run at https://wandb.ai/ruben-navasardyan4869-epfl/token-mix-moe/runs/noiou2md
wandb: WARNING Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 2000 that is less than the current step 2001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 3000 that is less than the current step 3001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 4000 that is less than the current step 4001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 5000 that is less than the current step 5001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 6000 that is less than the current step 6001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 7000 that is less than the current step 7001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 8000 that is less than the current step 8001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 9000 that is less than the current step 9001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 10000 that is less than the current step 10001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 11000 that is less than the current step 11001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 12000 that is less than the current step 12001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 13000 that is less than the current step 13001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 14000 that is less than the current step 14001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 15000 that is less than the current step 15001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 16000 that is less than the current step 16001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 17000 that is less than the current step 17001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 18000 that is less than the current step 18001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 19000 that is less than the current step 19001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 20000 that is less than the current step 20001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 21000 that is less than the current step 21001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 22000 that is less than the current step 22001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 23000 that is less than the current step 23001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 24000 that is less than the current step 24001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 25000 that is less than the current step 25001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 26000 that is less than the current step 26001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 27000 that is less than the current step 27001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 28000 that is less than the current step 28001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 29000 that is less than the current step 29001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 30000 that is less than the current step 30001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 31000 that is less than the current step 31001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 32000 that is less than the current step 32001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 33000 that is less than the current step 33001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 34000 that is less than the current step 34001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 35000 that is less than the current step 35001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 36000 that is less than the current step 36001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 37000 that is less than the current step 37001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 38000 that is less than the current step 38001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 39000 that is less than the current step 39001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 40000 that is less than the current step 40001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 41000 that is less than the current step 41001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 42000 that is less than the current step 42001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 43000 that is less than the current step 43001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 44000 that is less than the current step 44001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 45000 that is less than the current step 45001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 46000 that is less than the current step 46001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 47000 that is less than the current step 47001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 48000 that is less than the current step 48001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 49000 that is less than the current step 49001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 50000 that is less than the current step 50001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 51000 that is less than the current step 51001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 52000 that is less than the current step 52001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 53000 that is less than the current step 53001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 54000 that is less than the current step 54001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 55000 that is less than the current step 55001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 56000 that is less than the current step 56001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 57000 that is less than the current step 57001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 58000 that is less than the current step 58001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 59000 that is less than the current step 59001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 60000 that is less than the current step 60001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 61000 that is less than the current step 61001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 62000 that is less than the current step 62001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 63000 that is less than the current step 63001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 64000 that is less than the current step 64001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 65000 that is less than the current step 65001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 66000 that is less than the current step 66001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 67000 that is less than the current step 67001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 68000 that is less than the current step 68001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 69000 that is less than the current step 69001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 70000 that is less than the current step 70001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 71000 that is less than the current step 71001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 72000 that is less than the current step 72001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 73000 that is less than the current step 73001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 74000 that is less than the current step 74001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 75000 that is less than the current step 75001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 76000 that is less than the current step 76001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 77000 that is less than the current step 77001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 78000 that is less than the current step 78001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 79000 that is less than the current step 79001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 80000 that is less than the current step 80001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 81000 that is less than the current step 81001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 82000 that is less than the current step 82001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 83000 that is less than the current step 83001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 84000 that is less than the current step 84001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 85000 that is less than the current step 85001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 86000 that is less than the current step 86001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 87000 that is less than the current step 87001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 88000 that is less than the current step 88001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 89000 that is less than the current step 89001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 90000 that is less than the current step 90001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 91000 that is less than the current step 91001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 92000 that is less than the current step 92001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 93000 that is less than the current step 93001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 94000 that is less than the current step 94001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 95000 that is less than the current step 95001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 96000 that is less than the current step 96001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 97000 that is less than the current step 97001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 98000 that is less than the current step 98001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 99000 that is less than the current step 99001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Loading dataset 'slimpajama'
Num training tokens: 6553600001
Num validation tokens: 196214785
number of parameters: 255.71M
number of optimized parameters: 256.11M
using fused AdamW: True

Training model=base 
{'config_format': 'base', 'batch_size': 32, 'acc_steps': 4, 'seed': 0, 'data_seed': 1004, 'device': device(type='cuda', index=0), 'iterations': 100000, 'lr': 0.001, 'warmup_percent': 0.05, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'scheduler': 'cos', 'opt': 'adamw', 'eval_freq': 200, 'results_base_folder': './exps', 'grad_clip': 0.0, 'dataset': 'slimpajama', 'vocab_size': 50304, 'data_in_ram': False, 'model': 'base', 'use_pretrained': None, 'dropout': 0.0, 'n_head': 6, 'n_layer': 12, 'n_embd': 768, 'sequence_length': 512, 'dtype': torch.bfloat16, 'bias': False, 'compile': False, 'rmsnorm_eps': 1e-05, 'moe_num_experts': 7, 'moe_num_experts_per_tok': 1, 'moe_softmax_order': 'softmax_topk', 'moe_type': 'token_choice', 'mlp_dim_exp_factor': 4, 'moe_entropy_loss_factor': 0.001, 'moe_aux_loss_factor': 0.01, 'moe_z_loss_factor': 0.001, 'no_doge': False, 'moe_router_loss': 'load_balancing_only', 'multiple_of': 256, 'run_prefix': None, 'exp_name': 'base_lr0.001_bs32x4_seqlen512/run_id=20250915_222348_seed=0', 'wandb': True, 'wandb_project': 'token-mix-moe', 'wandb_run_prefix': 'none', 'eval_seq_prefix': 'Once upon a time', 'undefine_run_id': False, 'distributed_backend': None, 'save_checkpoint_freq': None, 'run_id': '20250915_222348', 'world_size': 1}

0/200 [train] loss=8.060 [val] loss=8.033, pp=3081.09, acc=0.113686 [time per itr] 147.35ms [lr] 0.00001
0/400 [train] loss=7.242 [val] loss=7.088, pp=1197.20, acc=0.142273 [time per itr] 146.39ms [lr] 0.00003
0/600 [train] loss=6.944 [val] loss=6.768, pp=869.76, acc=0.141276 [time per itr] 145.52ms [lr] 0.00004
0/800 [train] loss=6.485 [val] loss=6.439, pp=626.07, acc=0.154709 [time per itr] 152.30ms [lr] 0.00007
0/1000 [train] loss=6.310 [val] loss=6.226, pp=505.73, acc=0.167491 [time per itr] 152.94ms [lr] 0.00010
0/1200 [train] loss=6.268 [val] loss=6.049, pp=423.77, acc=0.176099 [time per itr] 152.78ms [lr] 0.00014
0/1400 [train] loss=5.959 [val] loss=5.914, pp=370.25, acc=0.180990 [time per itr] 152.47ms [lr] 0.00019
0/1600 [train] loss=5.974 [val] loss=5.743, pp=311.91, acc=0.191640 [time per itr] 152.49ms [lr] 0.00024
0/1800 [train] loss=5.748 [val] loss=5.692, pp=296.60, acc=0.193926 [time per itr] 153.61ms [lr] 0.00029
0/2000 [train] loss=5.573 [val] loss=5.505, pp=245.98, acc=0.205945 [time per itr] 152.38ms [lr] 0.00035
0/2200 [train] loss=5.667 [val] loss=5.285, pp=197.45, acc=0.232343 [time per itr] 154.20ms [lr] 0.00041
0/2400 [train] loss=5.016 [val] loss=5.220, pp=185.01, acc=0.235832 [time per itr] 152.87ms [lr] 0.00047
0/2600 [train] loss=5.395 [val] loss=5.156, pp=173.45, acc=0.243858 [time per itr] 151.33ms [lr] 0.00054
0/2800 [train] loss=4.648 [val] loss=5.083, pp=161.28, acc=0.252324 [time per itr] 151.38ms [lr] 0.00060
0/3000 [train] loss=5.096 [val] loss=5.007, pp=149.52, acc=0.258232 [time per itr] 151.08ms [lr] 0.00066
0/3200 [train] loss=5.060 [val] loss=4.924, pp=137.49, acc=0.267843 [time per itr] 151.50ms [lr] 0.00072
0/3400 [train] loss=4.715 [val] loss=4.924, pp=137.62, acc=0.263995 [time per itr] 152.21ms [lr] 0.00077
0/3600 [train] loss=5.083 [val] loss=4.794, pp=120.81, acc=0.281062 [time per itr] 152.20ms [lr] 0.00082
0/3800 [train] loss=4.745 [val] loss=4.805, pp=122.17, acc=0.278580 [time per itr] 151.83ms [lr] 0.00087
0/4000 [train] loss=4.791 [val] loss=4.823, pp=124.30, acc=0.273079 [time per itr] 151.34ms [lr] 0.00091
0/4200 [train] loss=5.062 [val] loss=4.758, pp=116.55, acc=0.279803 [time per itr] 151.85ms [lr] 0.00094
0/4400 [train] loss=4.865 [val] loss=4.739, pp=114.34, acc=0.280396 [time per itr] 153.01ms [lr] 0.00097
0/4600 [train] loss=4.708 [val] loss=4.742, pp=114.64, acc=0.278760 [time per itr] 152.76ms [lr] 0.00098
0/4800 [train] loss=4.702 [val] loss=4.653, pp=104.94, acc=0.287865 [time per itr] 151.61ms [lr] 0.00100
0/5000 [train] loss=4.865 [val] loss=4.611, pp=100.63, acc=0.290677 [time per itr] 151.73ms [lr] 0.00100
0/5200 [train] loss=4.648 [val] loss=4.519, pp=91.73, acc=0.305834 [time per itr] 151.85ms [lr] 0.00100
0/5400 [train] loss=4.431 [val] loss=4.597, pp=99.17, acc=0.291181 [time per itr] 151.85ms [lr] 0.00100
0/5600 [train] loss=4.709 [val] loss=4.526, pp=92.35, acc=0.301682 [time per itr] 152.21ms [lr] 0.00100
0/5800 [train] loss=4.560 [val] loss=4.509, pp=90.86, acc=0.302343 [time per itr] 151.07ms [lr] 0.00100
0/6000 [train] loss=4.147 [val] loss=4.516, pp=91.48, acc=0.301000 [time per itr] 150.49ms [lr] 0.00100
0/6200 [train] loss=4.572 [val] loss=4.430, pp=83.92, acc=0.308637 [time per itr] 150.48ms [lr] 0.00100
0/6400 [train] loss=4.515 [val] loss=4.464, pp=86.85, acc=0.308535 [time per itr] 153.79ms [lr] 0.00100
0/6600 [train] loss=4.442 [val] loss=4.416, pp=82.75, acc=0.307660 [time per itr] 157.91ms [lr] 0.00100
0/6800 [train] loss=4.761 [val] loss=4.337, pp=76.49, acc=0.321823 [time per itr] 155.11ms [lr] 0.00100
0/7000 [train] loss=4.191 [val] loss=4.396, pp=81.14, acc=0.309741 [time per itr] 158.52ms [lr] 0.00100
0/7200 [train] loss=4.476 [val] loss=4.424, pp=83.46, acc=0.307813 [time per itr] 158.58ms [lr] 0.00100
0/7400 [train] loss=4.370 [val] loss=4.302, pp=73.87, acc=0.323626 [time per itr] 154.96ms [lr] 0.00100
0/7600 [train] loss=4.551 [val] loss=4.347, pp=77.25, acc=0.318535 [time per itr] 153.12ms [lr] 0.00100
0/7800 [train] loss=4.107 [val] loss=4.345, pp=77.10, acc=0.319160 [time per itr] 159.18ms [lr] 0.00100
0/8000 [train] loss=4.247 [val] loss=4.290, pp=72.95, acc=0.324361 [time per itr] 155.41ms [lr] 0.00100
0/8200 [train] loss=4.487 [val] loss=4.320, pp=75.16, acc=0.318265 [time per itr] 153.23ms [lr] 0.00100
0/8400 [train] loss=4.415 [val] loss=4.291, pp=73.01, acc=0.323845 [time per itr] 153.11ms [lr] 0.00100
0/8600 [train] loss=4.226 [val] loss=4.317, pp=74.94, acc=0.318904 [time per itr] 153.33ms [lr] 0.00100
0/8800 [train] loss=4.159 [val] loss=4.252, pp=70.24, acc=0.328545 [time per itr] 152.82ms [lr] 0.00100
0/9000 [train] loss=4.280 [val] loss=4.239, pp=69.34, acc=0.327566 [time per itr] 153.52ms [lr] 0.00100
0/9200 [train] loss=4.199 [val] loss=4.259, pp=70.71, acc=0.324883 [time per itr] 153.84ms [lr] 0.00100
0/9400 [train] loss=4.190 [val] loss=4.192, pp=66.17, acc=0.333481 [time per itr] 153.68ms [lr] 0.00100
0/9600 [train] loss=4.113 [val] loss=4.259, pp=70.73, acc=0.323792 [time per itr] 153.21ms [lr] 0.00099
0/9800 [train] loss=4.019 [val] loss=4.239, pp=69.34, acc=0.324015 [time per itr] 153.11ms [lr] 0.00099
0/10000 [train] loss=4.426 [val] loss=4.221, pp=68.07, acc=0.330264 [time per itr] 154.09ms [lr] 0.00099
0/10200 [train] loss=3.939 [val] loss=4.171, pp=64.80, acc=0.336327 [time per itr] 158.44ms [lr] 0.00099
0/10400 [train] loss=3.913 [val] loss=4.225, pp=68.35, acc=0.326828 [time per itr] 155.92ms [lr] 0.00099
0/10600 [train] loss=3.975 [val] loss=4.197, pp=66.52, acc=0.330510 [time per itr] 167.99ms [lr] 0.00099
0/10800 [train] loss=4.081 [val] loss=4.305, pp=74.10, acc=0.315954 [time per itr] 154.68ms [lr] 0.00099
0/11000 [train] loss=3.989 [val] loss=4.177, pp=65.14, acc=0.332415 [time per itr] 152.67ms [lr] 0.00099
0/11200 [train] loss=4.230 [val] loss=4.181, pp=65.42, acc=0.333196 [time per itr] 152.60ms [lr] 0.00099
0/11400 [train] loss=3.948 [val] loss=4.145, pp=63.12, acc=0.335142 [time per itr] 154.88ms [lr] 0.00099
0/11600 [train] loss=4.327 [val] loss=4.218, pp=67.92, acc=0.330294 [time per itr] 153.19ms [lr] 0.00099
0/11800 [train] loss=3.991 [val] loss=4.147, pp=63.23, acc=0.335759 [time per itr] 152.36ms [lr] 0.00099
0/12000 [train] loss=4.235 [val] loss=4.196, pp=66.42, acc=0.327187 [time per itr] 152.32ms [lr] 0.00099
0/12200 [train] loss=4.310 [val] loss=4.137, pp=62.64, acc=0.337588 [time per itr] 153.60ms [lr] 0.00099
0/12400 [train] loss=4.075 [val] loss=4.147, pp=63.24, acc=0.334366 [time per itr] 152.81ms [lr] 0.00099
0/12600 [train] loss=4.071 [val] loss=4.192, pp=66.16, acc=0.324921 [time per itr] 153.83ms [lr] 0.00099
0/12800 [train] loss=3.915 [val] loss=4.151, pp=63.47, acc=0.332433 [time per itr] 157.61ms [lr] 0.00099
0/13000 [train] loss=4.136 [val] loss=4.152, pp=63.54, acc=0.331296 [time per itr] 154.07ms [lr] 0.00098
0/13200 [train] loss=4.208 [val] loss=4.078, pp=59.01, acc=0.343440 [time per itr] 158.02ms [lr] 0.00098
0/13400 [train] loss=4.016 [val] loss=4.121, pp=61.62, acc=0.333054 [time per itr] 157.01ms [lr] 0.00098
0/13600 [train] loss=4.261 [val] loss=4.115, pp=61.22, acc=0.337542 [time per itr] 154.19ms [lr] 0.00098
0/13800 [train] loss=4.179 [val] loss=4.156, pp=63.80, acc=0.330999 [time per itr] 152.36ms [lr] 0.00098
0/14000 [train] loss=4.085 [val] loss=4.099, pp=60.29, acc=0.336703 [time per itr] 153.05ms [lr] 0.00098
0/14200 [train] loss=4.182 [val] loss=4.108, pp=60.82, acc=0.338682 [time per itr] 154.38ms [lr] 0.00098
0/14400 [train] loss=4.190 [val] loss=4.071, pp=58.61, acc=0.343524 [time per itr] 152.87ms [lr] 0.00098
0/14600 [train] loss=3.994 [val] loss=4.108, pp=60.80, acc=0.337438 [time per itr] 155.30ms [lr] 0.00098
0/14800 [train] loss=4.233 [val] loss=4.079, pp=59.07, acc=0.337601 [time per itr] 152.30ms [lr] 0.00098
0/15000 [train] loss=4.072 [val] loss=4.091, pp=59.82, acc=0.337972 [time per itr] 152.06ms [lr] 0.00098
0/15200 [train] loss=4.002 [val] loss=4.137, pp=62.63, acc=0.334933 [time per itr] 153.95ms [lr] 0.00097
0/15400 [train] loss=4.046 [val] loss=4.087, pp=59.58, acc=0.338183 [time per itr] 152.64ms [lr] 0.00097
0/15600 [train] loss=4.033 [val] loss=4.083, pp=59.33, acc=0.339060 [time per itr] 152.34ms [lr] 0.00097
0/15800 [train] loss=4.383 [val] loss=4.058, pp=57.83, acc=0.342504 [time per itr] 152.20ms [lr] 0.00097
0/16000 [train] loss=3.910 [val] loss=4.013, pp=55.32, acc=0.350319 [time per itr] 152.23ms [lr] 0.00097
0/16200 [train] loss=4.379 [val] loss=4.083, pp=59.32, acc=0.339666 [time per itr] 153.19ms [lr] 0.00097
0/16400 [train] loss=3.989 [val] loss=4.115, pp=61.24, acc=0.337079 [time per itr] 153.28ms [lr] 0.00097
0/16600 [train] loss=4.187 [val] loss=4.077, pp=58.97, acc=0.339208 [time per itr] 153.78ms [lr] 0.00097
0/16800 [train] loss=4.057 [val] loss=4.080, pp=59.13, acc=0.341797 [time per itr] 153.22ms [lr] 0.00097
0/17000 [train] loss=4.178 [val] loss=4.044, pp=57.07, acc=0.342489 [time per itr] 152.85ms [lr] 0.00097
0/17200 [train] loss=3.855 [val] loss=4.019, pp=55.66, acc=0.347476 [time per itr] 152.91ms [lr] 0.00096
0/17400 [train] loss=4.127 [val] loss=4.065, pp=58.27, acc=0.337822 [time per itr] 153.16ms [lr] 0.00096
0/17600 [train] loss=3.978 [val] loss=4.060, pp=57.97, acc=0.343569 [time per itr] 152.34ms [lr] 0.00096
0/17800 [train] loss=3.977 [val] loss=4.067, pp=58.36, acc=0.341586 [time per itr] 154.65ms [lr] 0.00096
0/18000 [train] loss=4.010 [val] loss=4.084, pp=59.36, acc=0.338758 [time per itr] 153.43ms [lr] 0.00096
0/18200 [train] loss=4.134 [val] loss=3.988, pp=53.96, acc=0.349536 [time per itr] 153.37ms [lr] 0.00096
0/18400 [train] loss=4.110 [val] loss=4.001, pp=54.66, acc=0.347321 [time per itr] 153.40ms [lr] 0.00096
0/18600 [train] loss=4.098 [val] loss=4.047, pp=57.25, acc=0.344353 [time per itr] 152.80ms [lr] 0.00096
0/18800 [train] loss=4.156 [val] loss=4.037, pp=56.65, acc=0.344465 [time per itr] 152.53ms [lr] 0.00095
0/19000 [train] loss=3.870 [val] loss=4.023, pp=55.86, acc=0.347766 [time per itr] 153.42ms [lr] 0.00095
0/19200 [train] loss=4.007 [val] loss=3.970, pp=53.00, acc=0.351346 [time per itr] 159.16ms [lr] 0.00095
0/19400 [train] loss=3.613 [val] loss=4.020, pp=55.71, acc=0.345983 [time per itr] 157.33ms [lr] 0.00095
0/19600 [train] loss=3.883 [val] loss=4.067, pp=58.39, acc=0.336868 [time per itr] 153.38ms [lr] 0.00095
0/19800 [train] loss=3.983 [val] loss=3.956, pp=52.22, acc=0.354619 [time per itr] 156.63ms [lr] 0.00095
0/20000 [train] loss=3.873 [val] loss=4.026, pp=56.03, acc=0.343147 [time per itr] 152.61ms [lr] 0.00095
0/20200 [train] loss=3.951 [val] loss=3.988, pp=53.93, acc=0.351626 [time per itr] 152.86ms [lr] 0.00094
0/20400 [train] loss=3.912 [val] loss=3.959, pp=52.42, acc=0.352580 [time per itr] 154.65ms [lr] 0.00094
0/20600 [train] loss=3.699 [val] loss=3.974, pp=53.18, acc=0.351596 [time per itr] 152.29ms [lr] 0.00094
0/20800 [train] loss=3.991 [val] loss=4.020, pp=55.73, acc=0.342466 [time per itr] 162.03ms [lr] 0.00094
0/21000 [train] loss=3.950 [val] loss=3.970, pp=52.99, acc=0.352974 [time per itr] 152.13ms [lr] 0.00094
0/21200 [train] loss=4.208 [val] loss=3.957, pp=52.29, acc=0.353416 [time per itr] 152.53ms [lr] 0.00094
0/21400 [train] loss=4.125 [val] loss=3.999, pp=54.54, acc=0.346802 [time per itr] 152.09ms [lr] 0.00094
0/21600 [train] loss=4.063 [val] loss=4.012, pp=55.28, acc=0.347438 [time per itr] 152.87ms [lr] 0.00093
0/21800 [train] loss=4.016 [val] loss=3.996, pp=54.36, acc=0.345980 [time per itr] 153.63ms [lr] 0.00093
0/22000 [train] loss=3.921 [val] loss=3.983, pp=53.66, acc=0.350845 [time per itr] 151.86ms [lr] 0.00093
0/22200 [train] loss=4.106 [val] loss=3.943, pp=51.56, acc=0.352903 [time per itr] 152.69ms [lr] 0.00093
0/22400 [train] loss=4.178 [val] loss=4.008, pp=55.03, acc=0.340088 [time per itr] 153.47ms [lr] 0.00093
0/22600 [train] loss=3.915 [val] loss=4.034, pp=56.47, acc=0.343013 [time per itr] 151.97ms [lr] 0.00093
0/22800 [train] loss=3.644 [val] loss=3.961, pp=52.53, acc=0.352984 [time per itr] 152.53ms [lr] 0.00092
0/23000 [train] loss=3.847 [val] loss=3.935, pp=51.17, acc=0.357160 [time per itr] 153.33ms [lr] 0.00092
0/23200 [train] loss=4.227 [val] loss=3.970, pp=52.98, acc=0.353986 [time per itr] 152.64ms [lr] 0.00092
0/23400 [train] loss=3.895 [val] loss=4.054, pp=57.64, acc=0.340741 [time per itr] 158.14ms [lr] 0.00092
0/23600 [train] loss=3.979 [val] loss=3.932, pp=51.03, acc=0.355329 [time per itr] 152.62ms [lr] 0.00092
0/23800 [train] loss=4.198 [val] loss=3.965, pp=52.72, acc=0.350281 [time per itr] 152.50ms [lr] 0.00092
0/24000 [train] loss=3.848 [val] loss=3.982, pp=53.61, acc=0.350899 [time per itr] 152.34ms [lr] 0.00091
0/24200 [train] loss=3.884 [val] loss=3.939, pp=51.38, acc=0.354894 [time per itr] 152.46ms [lr] 0.00091
0/24400 [train] loss=3.766 [val] loss=3.928, pp=50.81, acc=0.360822 [time per itr] 152.84ms [lr] 0.00091
0/24600 [train] loss=3.587 [val] loss=3.908, pp=49.80, acc=0.360036 [time per itr] 152.77ms [lr] 0.00091
0/24800 [train] loss=4.088 [val] loss=3.905, pp=49.66, acc=0.358157 [time per itr] 151.58ms [lr] 0.00091
0/25000 [train] loss=3.930 [val] loss=3.959, pp=52.40, acc=0.351240 [time per itr] 151.36ms [lr] 0.00091
0/25200 [train] loss=3.827 [val] loss=3.947, pp=51.79, acc=0.354919 [time per itr] 152.45ms [lr] 0.00090
0/25400 [train] loss=3.910 [val] loss=3.980, pp=53.54, acc=0.345749 [time per itr] 153.23ms [lr] 0.00090
0/25600 [train] loss=3.976 [val] loss=3.923, pp=50.53, acc=0.354988 [time per itr] 152.45ms [lr] 0.00090
0/25800 [train] loss=3.970 [val] loss=3.956, pp=52.23, acc=0.354726 [time per itr] 152.26ms [lr] 0.00090
0/26000 [train] loss=3.808 [val] loss=3.891, pp=48.97, acc=0.362264 [time per itr] 151.85ms [lr] 0.00090
0/26200 [train] loss=3.953 [val] loss=3.883, pp=48.56, acc=0.360868 [time per itr] 152.51ms [lr] 0.00089
0/26400 [train] loss=3.773 [val] loss=3.925, pp=50.66, acc=0.357430 [time per itr] 155.51ms [lr] 0.00089
0/26600 [train] loss=3.979 [val] loss=3.992, pp=54.17, acc=0.350207 [time per itr] 163.27ms [lr] 0.00089
0/26800 [train] loss=3.724 [val] loss=3.896, pp=49.21, acc=0.359482 [time per itr] 153.96ms [lr] 0.00089
0/27000 [train] loss=4.003 [val] loss=3.955, pp=52.20, acc=0.352809 [time per itr] 158.87ms [lr] 0.00089
0/27200 [train] loss=4.274 [val] loss=3.892, pp=49.00, acc=0.358266 [time per itr] 154.54ms [lr] 0.00088
0/27400 [train] loss=3.893 [val] loss=3.909, pp=49.84, acc=0.356929 [time per itr] 166.18ms [lr] 0.00088
0/27600 [train] loss=3.943 [val] loss=3.949, pp=51.90, acc=0.349538 [time per itr] 152.49ms [lr] 0.00088
0/27800 [train] loss=4.100 [val] loss=3.916, pp=50.21, acc=0.354057 [time per itr] 152.30ms [lr] 0.00088
0/28000 [train] loss=4.251 [val] loss=3.942, pp=51.53, acc=0.354739 [time per itr] 152.45ms [lr] 0.00088
0/28200 [train] loss=3.860 [val] loss=3.946, pp=51.75, acc=0.351687 [time per itr] 163.37ms [lr] 0.00087
0/28400 [train] loss=3.946 [val] loss=3.913, pp=50.05, acc=0.355698 [time per itr] 161.21ms [lr] 0.00087
0/28600 [train] loss=4.035 [val] loss=3.870, pp=47.94, acc=0.361226 [time per itr] 153.21ms [lr] 0.00087
0/28800 [train] loss=3.580 [val] loss=3.917, pp=50.23, acc=0.352982 [time per itr] 153.66ms [lr] 0.00087
0/29000 [train] loss=3.820 [val] loss=3.907, pp=49.74, acc=0.358144 [time per itr] 153.19ms [lr] 0.00087
0/29200 [train] loss=4.079 [val] loss=3.879, pp=48.39, acc=0.359131 [time per itr] 154.09ms [lr] 0.00086
0/29400 [train] loss=3.740 [val] loss=3.948, pp=51.82, acc=0.354027 [time per itr] 153.04ms [lr] 0.00086
0/29600 [train] loss=3.910 [val] loss=3.880, pp=48.41, acc=0.361232 [time per itr] 152.34ms [lr] 0.00086
0/29800 [train] loss=3.892 [val] loss=3.868, pp=47.83, acc=0.359365 [time per itr] 152.73ms [lr] 0.00086
0/30000 [train] loss=3.947 [val] loss=3.869, pp=47.90, acc=0.360382 [time per itr] 152.54ms [lr] 0.00085
0/30200 [train] loss=3.906 [val] loss=3.922, pp=50.50, acc=0.355563 [time per itr] 152.31ms [lr] 0.00085
0/30400 [train] loss=3.985 [val] loss=3.898, pp=49.30, acc=0.361862 [time per itr] 151.84ms [lr] 0.00085
0/30600 [train] loss=3.863 [val] loss=3.923, pp=50.53, acc=0.356049 [time per itr] 152.51ms [lr] 0.00085
0/30800 [train] loss=4.095 [val] loss=3.926, pp=50.68, acc=0.354813 [time per itr] 153.04ms [lr] 0.00085
0/31000 [train] loss=3.915 [val] loss=3.901, pp=49.47, acc=0.355937 [time per itr] 153.97ms [lr] 0.00084
0/31200 [train] loss=4.044 [val] loss=3.947, pp=51.80, acc=0.351318 [time per itr] 153.48ms [lr] 0.00084
0/31400 [train] loss=3.684 [val] loss=3.861, pp=47.52, acc=0.364591 [time per itr] 152.60ms [lr] 0.00084
0/31600 [train] loss=4.067 [val] loss=3.848, pp=46.88, acc=0.369420 [time per itr] 152.76ms [lr] 0.00084
0/31800 [train] loss=3.700 [val] loss=3.952, pp=52.04, acc=0.351359 [time per itr] 152.73ms [lr] 0.00083
0/32000 [train] loss=4.060 [val] loss=3.904, pp=49.58, acc=0.359985 [time per itr] 152.06ms [lr] 0.00083
0/32200 [train] loss=3.951 [val] loss=3.882, pp=48.51, acc=0.358788 [time per itr] 152.40ms [lr] 0.00083
0/32400 [train] loss=3.879 [val] loss=3.889, pp=48.88, acc=0.358897 [time per itr] 154.04ms [lr] 0.00083
0/32600 [train] loss=3.809 [val] loss=3.865, pp=47.71, acc=0.363927 [time per itr] 152.73ms [lr] 0.00083
0/32800 [train] loss=3.886 [val] loss=3.920, pp=50.38, acc=0.356806 [time per itr] 152.42ms [lr] 0.00082
0/33000 [train] loss=3.545 [val] loss=3.933, pp=51.04, acc=0.349930 [time per itr] 152.13ms [lr] 0.00082
0/33200 [train] loss=3.586 [val] loss=3.786, pp=44.08, acc=0.373634 [time per itr] 152.31ms [lr] 0.00082
0/33400 [train] loss=4.035 [val] loss=3.886, pp=48.71, acc=0.359334 [time per itr] 153.13ms [lr] 0.00082
0/33600 [train] loss=3.964 [val] loss=3.851, pp=47.05, acc=0.363589 [time per itr] 153.84ms [lr] 0.00081
0/33800 [train] loss=3.759 [val] loss=3.869, pp=47.90, acc=0.360664 [time per itr] 152.56ms [lr] 0.00081
0/34000 [train] loss=4.176 [val] loss=3.873, pp=48.11, acc=0.362264 [time per itr] 152.24ms [lr] 0.00081
0/34200 [train] loss=3.817 [val] loss=3.945, pp=51.66, acc=0.350769 [time per itr] 152.80ms [lr] 0.00081
0/34400 [train] loss=3.543 [val] loss=3.875, pp=48.19, acc=0.360509 [time per itr] 157.77ms [lr] 0.00080
0/34600 [train] loss=3.593 [val] loss=3.847, pp=46.83, acc=0.364293 [time per itr] 155.96ms [lr] 0.00080
0/34800 [train] loss=3.575 [val] loss=3.931, pp=50.94, acc=0.351298 [time per itr] 156.59ms [lr] 0.00080
0/35000 [train] loss=3.936 [val] loss=3.859, pp=47.41, acc=0.364276 [time per itr] 152.45ms [lr] 0.00080
0/35200 [train] loss=3.682 [val] loss=3.899, pp=49.34, acc=0.354200 [time per itr] 152.10ms [lr] 0.00079
0/35400 [train] loss=4.180 [val] loss=3.868, pp=47.85, acc=0.360934 [time per itr] 152.99ms [lr] 0.00079
0/35600 [train] loss=3.778 [val] loss=3.889, pp=48.86, acc=0.354533 [time per itr] 152.28ms [lr] 0.00079
0/35800 [train] loss=3.665 [val] loss=3.874, pp=48.15, acc=0.361214 [time per itr] 152.49ms [lr] 0.00079
0/36000 [train] loss=4.072 [val] loss=3.835, pp=46.29, acc=0.367701 [time per itr] 152.87ms [lr] 0.00078
0/36200 [train] loss=3.918 [val] loss=3.853, pp=47.14, acc=0.363223 [time per itr] 153.28ms [lr] 0.00078
0/36400 [train] loss=4.058 [val] loss=3.963, pp=52.59, acc=0.351860 [time per itr] 154.37ms [lr] 0.00078
0/36600 [train] loss=3.675 [val] loss=3.853, pp=47.14, acc=0.361554 [time per itr] 152.59ms [lr] 0.00078
0/36800 [train] loss=3.898 [val] loss=3.878, pp=48.34, acc=0.359688 [time per itr] 152.67ms [lr] 0.00077
0/37000 [train] loss=3.969 [val] loss=3.946, pp=51.70, acc=0.350121 [time per itr] 152.17ms [lr] 0.00077
0/37200 [train] loss=4.053 [val] loss=3.852, pp=47.08, acc=0.358599 [time per itr] 152.43ms [lr] 0.00077
0/37400 [train] loss=3.940 [val] loss=3.861, pp=47.50, acc=0.360558 [time per itr] 156.67ms [lr] 0.00077
0/37600 [train] loss=3.815 [val] loss=3.897, pp=49.25, acc=0.356435 [time per itr] 156.43ms [lr] 0.00076
0/37800 [train] loss=3.779 [val] loss=3.866, pp=47.73, acc=0.364347 [time per itr] 152.72ms [lr] 0.00076
0/38000 [train] loss=3.838 [val] loss=3.849, pp=46.95, acc=0.365766 [time per itr] 153.83ms [lr] 0.00076
0/38200 [train] loss=3.853 [val] loss=3.840, pp=46.53, acc=0.363602 [time per itr] 151.90ms [lr] 0.00075
0/38400 [train] loss=3.777 [val] loss=3.877, pp=48.26, acc=0.355471 [time per itr] 152.02ms [lr] 0.00075
0/38600 [train] loss=3.995 [val] loss=3.802, pp=44.80, acc=0.369125 [time per itr] 152.53ms [lr] 0.00075
0/38800 [train] loss=3.538 [val] loss=3.805, pp=44.92, acc=0.373286 [time per itr] 152.22ms [lr] 0.00075
0/39000 [train] loss=3.799 [val] loss=3.883, pp=48.59, acc=0.358994 [time per itr] 153.17ms [lr] 0.00074
0/39200 [train] loss=4.158 [val] loss=3.859, pp=47.41, acc=0.363154 [time per itr] 151.87ms [lr] 0.00074
0/39400 [train] loss=3.841 [val] loss=3.779, pp=43.76, acc=0.370794 [time per itr] 151.48ms [lr] 0.00074
0/39600 [train] loss=3.760 [val] loss=3.844, pp=46.72, acc=0.364123 [time per itr] 154.16ms [lr] 0.00074
0/39800 [train] loss=4.012 [val] loss=3.826, pp=45.87, acc=0.366643 [time per itr] 175.61ms [lr] 0.00073
0/40000 [train] loss=3.633 [val] loss=3.827, pp=45.92, acc=0.365130 [time per itr] 169.24ms [lr] 0.00073
0/40200 [train] loss=3.967 [val] loss=3.838, pp=46.45, acc=0.365117 [time per itr] 155.84ms [lr] 0.00073
0/40400 [train] loss=3.922 [val] loss=3.857, pp=47.30, acc=0.360463 [time per itr] 152.36ms [lr] 0.00073
0/40600 [train] loss=3.725 [val] loss=3.809, pp=45.10, acc=0.365865 [time per itr] 151.29ms [lr] 0.00072
0/40800 [train] loss=4.175 [val] loss=3.869, pp=47.90, acc=0.357180 [time per itr] 151.81ms [lr] 0.00072
0/41000 [train] loss=3.571 [val] loss=3.810, pp=45.15, acc=0.367625 [time per itr] 152.92ms [lr] 0.00072
0/41200 [train] loss=3.614 [val] loss=3.797, pp=44.56, acc=0.369492 [time per itr] 151.85ms [lr] 0.00071
0/41400 [train] loss=3.650 [val] loss=3.789, pp=44.20, acc=0.370837 [time per itr] 153.13ms [lr] 0.00071
0/41600 [train] loss=3.844 [val] loss=3.837, pp=46.40, acc=0.364922 [time per itr] 152.46ms [lr] 0.00071
0/41800 [train] loss=3.899 [val] loss=3.812, pp=45.26, acc=0.366142 [time per itr] 152.34ms [lr] 0.00071
0/42000 [train] loss=3.999 [val] loss=3.812, pp=45.25, acc=0.367701 [time per itr] 152.29ms [lr] 0.00070
0/42200 [train] loss=3.764 [val] loss=3.804, pp=44.86, acc=0.368518 [time per itr] 152.21ms [lr] 0.00070
0/42400 [train] loss=3.878 [val] loss=3.800, pp=44.72, acc=0.366247 [time per itr] 152.45ms [lr] 0.00070
0/42600 [train] loss=3.519 [val] loss=3.869, pp=47.89, acc=0.359698 [time per itr] 152.28ms [lr] 0.00069
0/42800 [train] loss=4.040 [val] loss=3.847, pp=46.88, acc=0.364657 [time per itr] 152.94ms [lr] 0.00069
0/43000 [train] loss=4.004 [val] loss=3.843, pp=46.65, acc=0.361384 [time per itr] 152.66ms [lr] 0.00069
0/43200 [train] loss=3.659 [val] loss=3.850, pp=47.01, acc=0.358777 [time per itr] 153.10ms [lr] 0.00069
0/43400 [train] loss=3.725 [val] loss=3.891, pp=48.94, acc=0.355789 [time per itr] 152.40ms [lr] 0.00068
0/43600 [train] loss=3.677 [val] loss=3.841, pp=46.56, acc=0.361811 [time per itr] 152.44ms [lr] 0.00068
0/43800 [train] loss=3.990 [val] loss=3.834, pp=46.27, acc=0.361277 [time per itr] 153.04ms [lr] 0.00068
0/44000 [train] loss=3.753 [val] loss=3.790, pp=44.24, acc=0.367716 [time per itr] 152.10ms [lr] 0.00067
0/44200 [train] loss=4.015 [val] loss=3.709, pp=40.80, acc=0.383087 [time per itr] 152.55ms [lr] 0.00067
0/44400 [train] loss=3.730 [val] loss=3.799, pp=44.65, acc=0.367640 [time per itr] 152.38ms [lr] 0.00067
0/44600 [train] loss=3.706 [val] loss=3.775, pp=43.59, acc=0.368556 [time per itr] 152.51ms [lr] 0.00067
0/44800 [train] loss=3.699 [val] loss=3.885, pp=48.69, acc=0.359858 [time per itr] 152.79ms [lr] 0.00066
0/45000 [train] loss=3.805 [val] loss=3.822, pp=45.70, acc=0.364510 [time per itr] 152.40ms [lr] 0.00066
0/45200 [train] loss=3.689 [val] loss=3.793, pp=44.38, acc=0.367556 [time per itr] 152.29ms [lr] 0.00066
0/45400 [train] loss=3.821 [val] loss=3.803, pp=44.84, acc=0.365807 [time per itr] 151.88ms [lr] 0.00065
0/45600 [train] loss=3.593 [val] loss=3.796, pp=44.52, acc=0.368566 [time per itr] 153.36ms [lr] 0.00065
0/45800 [train] loss=3.934 [val] loss=3.790, pp=44.26, acc=0.369532 [time per itr] 152.14ms [lr] 0.00065
0/46000 [train] loss=3.949 [val] loss=3.781, pp=43.87, acc=0.369461 [time per itr] 151.83ms [lr] 0.00065
0/46200 [train] loss=3.793 [val] loss=3.831, pp=46.09, acc=0.364245 [time per itr] 152.44ms [lr] 0.00064
0/46400 [train] loss=3.598 [val] loss=3.868, pp=47.83, acc=0.360820 [time per itr] 152.97ms [lr] 0.00064
0/46600 [train] loss=3.802 [val] loss=3.760, pp=42.96, acc=0.372630 [time per itr] 152.60ms [lr] 0.00064
0/46800 [train] loss=4.080 [val] loss=3.775, pp=43.61, acc=0.373174 [time per itr] 157.64ms [lr] 0.00063
0/47000 [train] loss=4.012 [val] loss=3.859, pp=47.43, acc=0.357226 [time per itr] 167.82ms [lr] 0.00063
0/47200 [train] loss=3.965 [val] loss=3.777, pp=43.69, acc=0.371112 [time per itr] 155.75ms [lr] 0.00063
0/47400 [train] loss=3.847 [val] loss=3.874, pp=48.15, acc=0.355848 [time per itr] 152.81ms [lr] 0.00063
0/47600 [train] loss=3.893 [val] loss=3.775, pp=43.60, acc=0.369598 [time per itr] 155.96ms [lr] 0.00062
0/47800 [train] loss=3.683 [val] loss=3.784, pp=44.00, acc=0.371302 [time per itr] 154.00ms [lr] 0.00062
0/48000 [train] loss=3.517 [val] loss=3.845, pp=46.76, acc=0.360224 [time per itr] 153.38ms [lr] 0.00062
0/48200 [train] loss=3.879 [val] loss=3.800, pp=44.71, acc=0.367859 [time per itr] 151.97ms [lr] 0.00061
0/48400 [train] loss=3.877 [val] loss=3.689, pp=40.00, acc=0.380951 [time per itr] 151.64ms [lr] 0.00061
0/48600 [train] loss=3.979 [val] loss=3.775, pp=43.58, acc=0.370509 [time per itr] 152.10ms [lr] 0.00061
0/48800 [train] loss=3.842 [val] loss=3.777, pp=43.67, acc=0.372073 [time per itr] 152.62ms [lr] 0.00060
0/49000 [train] loss=3.763 [val] loss=3.804, pp=44.90, acc=0.366862 [time per itr] 151.90ms [lr] 0.00060
0/49200 [train] loss=3.437 [val] loss=3.755, pp=42.74, acc=0.373998 [time per itr] 153.11ms [lr] 0.00060
0/49400 [train] loss=3.596 [val] loss=3.801, pp=44.75, acc=0.369329 [time per itr] 152.07ms [lr] 0.00060
0/49600 [train] loss=3.351 [val] loss=3.875, pp=48.16, acc=0.352857 [time per itr] 151.91ms [lr] 0.00059
0/49800 [train] loss=3.945 [val] loss=3.867, pp=47.79, acc=0.358561 [time per itr] 155.59ms [lr] 0.00059
0/50000 [train] loss=3.834 [val] loss=3.806, pp=44.95, acc=0.365290 [time per itr] 160.72ms [lr] 0.00059
0/50200 [train] loss=3.614 [val] loss=3.744, pp=42.25, acc=0.372332 [time per itr] 151.82ms [lr] 0.00058
0/50400 [train] loss=3.557 [val] loss=3.704, pp=40.63, acc=0.380882 [time per itr] 151.43ms [lr] 0.00058
0/50600 [train] loss=3.530 [val] loss=3.741, pp=42.13, acc=0.375224 [time per itr] 152.15ms [lr] 0.00058
0/50800 [train] loss=3.677 [val] loss=3.865, pp=47.72, acc=0.357445 [time per itr] 151.84ms [lr] 0.00058
0/51000 [train] loss=4.011 [val] loss=3.773, pp=43.51, acc=0.368624 [time per itr] 153.74ms [lr] 0.00057
0/51200 [train] loss=3.866 [val] loss=3.810, pp=45.15, acc=0.365832 [time per itr] 152.12ms [lr] 0.00057
0/51400 [train] loss=3.847 [val] loss=3.769, pp=43.35, acc=0.369542 [time per itr] 152.88ms [lr] 0.00057
0/51600 [train] loss=3.810 [val] loss=3.777, pp=43.70, acc=0.367930 [time per itr] 151.79ms [lr] 0.00056
0/51800 [train] loss=3.897 [val] loss=3.774, pp=43.57, acc=0.369377 [time per itr] 161.31ms [lr] 0.00056
0/52000 [train] loss=3.662 [val] loss=3.710, pp=40.85, acc=0.378489 [time per itr] 152.32ms [lr] 0.00056
0/52200 [train] loss=3.835 [val] loss=3.776, pp=43.62, acc=0.371262 [time per itr] 152.49ms [lr] 0.00055
0/52400 [train] loss=3.928 [val] loss=3.764, pp=43.13, acc=0.372063 [time per itr] 154.06ms [lr] 0.00055
0/52600 [train] loss=3.730 [val] loss=3.766, pp=43.19, acc=0.374255 [time per itr] 156.15ms [lr] 0.00055
0/52800 [train] loss=3.542 [val] loss=3.718, pp=41.19, acc=0.376322 [time per itr] 152.90ms [lr] 0.00055
0/53000 [train] loss=3.657 [val] loss=3.773, pp=43.52, acc=0.369288 [time per itr] 152.44ms [lr] 0.00054
0/53200 [train] loss=3.825 [val] loss=3.781, pp=43.86, acc=0.368736 [time per itr] 152.44ms [lr] 0.00054
0/53400 [train] loss=3.862 [val] loss=3.802, pp=44.78, acc=0.367065 [time per itr] 155.54ms [lr] 0.00054
0/53600 [train] loss=3.806 [val] loss=3.736, pp=41.94, acc=0.373945 [time per itr] 160.43ms [lr] 0.00053
0/53800 [train] loss=3.752 [val] loss=3.793, pp=44.40, acc=0.367910 [time per itr] 157.08ms [lr] 0.00053
0/54000 [train] loss=3.690 [val] loss=3.747, pp=42.39, acc=0.372027 [time per itr] 151.55ms [lr] 0.00053
0/54200 [train] loss=3.753 [val] loss=3.743, pp=42.24, acc=0.370939 [time per itr] 153.12ms [lr] 0.00052
0/54400 [train] loss=3.818 [val] loss=3.720, pp=41.27, acc=0.375961 [time per itr] 152.11ms [lr] 0.00052
0/54600 [train] loss=3.597 [val] loss=3.762, pp=43.05, acc=0.369189 [time per itr] 152.25ms [lr] 0.00052
0/54800 [train] loss=3.805 [val] loss=3.718, pp=41.19, acc=0.374448 [time per itr] 151.52ms [lr] 0.00052
0/55000 [train] loss=3.678 [val] loss=3.725, pp=41.48, acc=0.376409 [time per itr] 151.82ms [lr] 0.00051
0/55200 [train] loss=3.896 [val] loss=3.769, pp=43.32, acc=0.370641 [time per itr] 151.99ms [lr] 0.00051
0/55400 [train] loss=3.496 [val] loss=3.738, pp=42.00, acc=0.373133 [time per itr] 152.45ms [lr] 0.00051
0/55600 [train] loss=3.647 [val] loss=3.682, pp=39.72, acc=0.382993 [time per itr] 153.95ms [lr] 0.00050
0/55800 [train] loss=3.989 [val] loss=3.764, pp=43.11, acc=0.370392 [time per itr] 159.03ms [lr] 0.00050
0/56000 [train] loss=3.678 [val] loss=3.653, pp=38.58, acc=0.388710 [time per itr] 159.34ms [lr] 0.00050
0/56200 [train] loss=3.718 [val] loss=3.722, pp=41.33, acc=0.375448 [time per itr] 158.36ms [lr] 0.00050
0/56400 [train] loss=3.855 [val] loss=3.756, pp=42.79, acc=0.369947 [time per itr] 161.90ms [lr] 0.00049
0/56600 [train] loss=3.339 [val] loss=3.700, pp=40.46, acc=0.378596 [time per itr] 159.70ms [lr] 0.00049
0/56800 [train] loss=3.879 [val] loss=3.751, pp=42.57, acc=0.374547 [time per itr] 152.56ms [lr] 0.00049
0/57000 [train] loss=3.835 [val] loss=3.783, pp=43.96, acc=0.367032 [time per itr] 153.33ms [lr] 0.00048
0/57200 [train] loss=3.756 [val] loss=3.765, pp=43.16, acc=0.370443 [time per itr] 152.32ms [lr] 0.00048
0/57400 [train] loss=3.730 [val] loss=3.751, pp=42.58, acc=0.369102 [time per itr] 153.00ms [lr] 0.00048
0/57600 [train] loss=3.771 [val] loss=3.705, pp=40.63, acc=0.379339 [time per itr] 161.20ms [lr] 0.00047
0/57800 [train] loss=3.775 [val] loss=3.731, pp=41.71, acc=0.373085 [time per itr] 152.50ms [lr] 0.00047
0/58000 [train] loss=3.502 [val] loss=3.710, pp=40.87, acc=0.375735 [time per itr] 152.46ms [lr] 0.00047
0/58200 [train] loss=3.750 [val] loss=3.693, pp=40.16, acc=0.378906 [time per itr] 152.51ms [lr] 0.00047
0/58400 [train] loss=3.521 [val] loss=3.669, pp=39.23, acc=0.381516 [time per itr] 152.06ms [lr] 0.00046
0/58600 [train] loss=3.499 [val] loss=3.699, pp=40.40, acc=0.376066 [time per itr] 152.58ms [lr] 0.00046
0/58800 [train] loss=3.511 [val] loss=3.700, pp=40.43, acc=0.380198 [time per itr] 156.76ms [lr] 0.00046
0/59000 [train] loss=3.602 [val] loss=3.761, pp=42.98, acc=0.371539 [time per itr] 152.89ms [lr] 0.00045
0/59200 [train] loss=3.959 [val] loss=3.700, pp=40.46, acc=0.378126 [time per itr] 152.86ms [lr] 0.00045
0/59400 [train] loss=3.751 [val] loss=3.693, pp=40.15, acc=0.378779 [time per itr] 152.92ms [lr] 0.00045
0/59600 [train] loss=3.843 [val] loss=3.772, pp=43.48, acc=0.369904 [time per itr] 151.86ms [lr] 0.00045
0/59800 [train] loss=3.674 [val] loss=3.723, pp=41.40, acc=0.376137 [time per itr] 152.22ms [lr] 0.00044
0/60000 [train] loss=3.724 [val] loss=3.650, pp=38.48, acc=0.384928 [time per itr] 152.77ms [lr] 0.00044
0/60200 [train] loss=3.498 [val] loss=3.694, pp=40.22, acc=0.377388 [time per itr] 152.25ms [lr] 0.00044
0/60400 [train] loss=3.545 [val] loss=3.678, pp=39.55, acc=0.381770 [time per itr] 152.16ms [lr] 0.00043
0/60600 [train] loss=3.916 [val] loss=3.719, pp=41.23, acc=0.376190 [time per itr] 152.73ms [lr] 0.00043
0/60800 [train] loss=3.739 [val] loss=3.691, pp=40.09, acc=0.378563 [time per itr] 151.57ms [lr] 0.00043
0/61000 [train] loss=3.717 [val] loss=3.733, pp=41.82, acc=0.373556 [time per itr] 153.10ms [lr] 0.00043
0/61200 [train] loss=3.477 [val] loss=3.701, pp=40.48, acc=0.376300 [time per itr] 153.34ms [lr] 0.00042
0/61400 [train] loss=3.876 [val] loss=3.708, pp=40.78, acc=0.375931 [time per itr] 152.11ms [lr] 0.00042
0/61600 [train] loss=3.734 [val] loss=3.773, pp=43.53, acc=0.370822 [time per itr] 152.82ms [lr] 0.00042
0/61800 [train] loss=3.908 [val] loss=3.683, pp=39.75, acc=0.379667 [time per itr] 152.73ms [lr] 0.00041
0/62000 [train] loss=3.591 [val] loss=3.686, pp=39.89, acc=0.380152 [time per itr] 152.70ms [lr] 0.00041
0/62200 [train] loss=3.545 [val] loss=3.695, pp=40.23, acc=0.377268 [time per itr] 152.39ms [lr] 0.00041
0/62400 [train] loss=3.698 [val] loss=3.664, pp=39.00, acc=0.381243 [time per itr] 152.23ms [lr] 0.00041
0/62600 [train] loss=3.967 [val] loss=3.729, pp=41.64, acc=0.370817 [time per itr] 152.03ms [lr] 0.00040
0/62800 [train] loss=3.594 [val] loss=3.707, pp=40.73, acc=0.376183 [time per itr] 152.34ms [lr] 0.00040
0/63000 [train] loss=3.365 [val] loss=3.698, pp=40.35, acc=0.380669 [time per itr] 152.68ms [lr] 0.00040
0/63200 [train] loss=3.659 [val] loss=3.666, pp=39.09, acc=0.383021 [time per itr] 151.58ms [lr] 0.00039
0/63400 [train] loss=3.505 [val] loss=3.671, pp=39.28, acc=0.378543 [time per itr] 155.08ms [lr] 0.00039
0/63600 [train] loss=3.459 [val] loss=3.639, pp=38.06, acc=0.384109 [time per itr] 156.54ms [lr] 0.00039
0/63800 [train] loss=3.670 [val] loss=3.695, pp=40.23, acc=0.374308 [time per itr] 152.29ms [lr] 0.00039
0/64000 [train] loss=3.926 [val] loss=3.700, pp=40.44, acc=0.376834 [time per itr] 152.44ms [lr] 0.00038
0/64200 [train] loss=3.716 [val] loss=3.719, pp=41.22, acc=0.373411 [time per itr] 152.95ms [lr] 0.00038
0/64400 [train] loss=3.416 [val] loss=3.659, pp=38.82, acc=0.382914 [time per itr] 168.74ms [lr] 0.00038
0/64600 [train] loss=3.520 [val] loss=3.688, pp=39.95, acc=0.382591 [time per itr] 152.49ms [lr] 0.00037
0/64800 [train] loss=3.707 [val] loss=3.629, pp=37.69, acc=0.385384 [time per itr] 153.87ms [lr] 0.00037
0/65000 [train] loss=3.545 [val] loss=3.696, pp=40.29, acc=0.375852 [time per itr] 153.06ms [lr] 0.00037
0/65200 [train] loss=3.437 [val] loss=3.638, pp=38.01, acc=0.385002 [time per itr] 152.94ms [lr] 0.00037
0/65400 [train] loss=3.730 [val] loss=3.668, pp=39.16, acc=0.379486 [time per itr] 154.54ms [lr] 0.00036
0/65600 [train] loss=3.857 [val] loss=3.643, pp=38.20, acc=0.386996 [time per itr] 156.54ms [lr] 0.00036
0/65800 [train] loss=3.777 [val] loss=3.668, pp=39.18, acc=0.380959 [time per itr] 156.06ms [lr] 0.00036
0/66000 [train] loss=3.821 [val] loss=3.668, pp=39.17, acc=0.379166 [time per itr] 159.94ms [lr] 0.00036
0/66200 [train] loss=3.667 [val] loss=3.712, pp=40.93, acc=0.375585 [time per itr] 152.64ms [lr] 0.00035
0/66400 [train] loss=3.604 [val] loss=3.724, pp=41.42, acc=0.373339 [time per itr] 157.66ms [lr] 0.00035
0/66600 [train] loss=3.840 [val] loss=3.658, pp=38.78, acc=0.382268 [time per itr] 153.69ms [lr] 0.00035
0/66800 [train] loss=3.490 [val] loss=3.721, pp=41.29, acc=0.373065 [time per itr] 152.61ms [lr] 0.00035
0/67000 [train] loss=3.753 [val] loss=3.662, pp=38.94, acc=0.380124 [time per itr] 152.76ms [lr] 0.00034
0/67200 [train] loss=4.135 [val] loss=3.653, pp=38.58, acc=0.382683 [time per itr] 153.53ms [lr] 0.00034
0/67400 [train] loss=3.507 [val] loss=3.631, pp=37.74, acc=0.386457 [time per itr] 152.18ms [lr] 0.00034
0/67600 [train] loss=3.619 [val] loss=3.647, pp=38.37, acc=0.383443 [time per itr] 153.64ms [lr] 0.00033
0/67800 [train] loss=3.529 [val] loss=3.606, pp=36.82, acc=0.388980 [time per itr] 155.09ms [lr] 0.00033
0/68000 [train] loss=3.804 [val] loss=3.665, pp=39.06, acc=0.382350 [time per itr] 154.78ms [lr] 0.00033
0/68200 [train] loss=3.570 [val] loss=3.700, pp=40.43, acc=0.376999 [time per itr] 154.43ms [lr] 0.00033
0/68400 [train] loss=3.862 [val] loss=3.692, pp=40.13, acc=0.376144 [time per itr] 156.87ms [lr] 0.00032
0/68600 [train] loss=3.871 [val] loss=3.649, pp=38.43, acc=0.383553 [time per itr] 153.49ms [lr] 0.00032
0/68800 [train] loss=3.680 [val] loss=3.622, pp=37.40, acc=0.384542 [time per itr] 153.53ms [lr] 0.00032
0/69000 [train] loss=3.798 [val] loss=3.630, pp=37.70, acc=0.385109 [time per itr] 152.74ms [lr] 0.00032
0/69200 [train] loss=3.747 [val] loss=3.625, pp=37.54, acc=0.388654 [time per itr] 155.50ms [lr] 0.00031
0/69400 [train] loss=3.627 [val] loss=3.636, pp=37.92, acc=0.386856 [time per itr] 152.35ms [lr] 0.00031
0/69600 [train] loss=3.521 [val] loss=3.590, pp=36.23, acc=0.390129 [time per itr] 152.24ms [lr] 0.00031
0/69800 [train] loss=3.490 [val] loss=3.601, pp=36.63, acc=0.389371 [time per itr] 153.22ms [lr] 0.00031
0/70000 [train] loss=3.702 [val] loss=3.632, pp=37.79, acc=0.384420 [time per itr] 154.53ms [lr] 0.00030
0/70200 [train] loss=3.576 [val] loss=3.610, pp=36.98, acc=0.387296 [time per itr] 152.43ms [lr] 0.00030
0/70400 [train] loss=3.643 [val] loss=3.626, pp=37.55, acc=0.385646 [time per itr] 152.51ms [lr] 0.00030
0/70600 [train] loss=3.384 [val] loss=3.655, pp=38.67, acc=0.383926 [time per itr] 152.01ms [lr] 0.00030
0/70800 [train] loss=3.523 [val] loss=3.642, pp=38.15, acc=0.381350 [time per itr] 152.22ms [lr] 0.00029
0/71000 [train] loss=3.897 [val] loss=3.638, pp=38.03, acc=0.383102 [time per itr] 152.25ms [lr] 0.00029
0/71200 [train] loss=3.802 [val] loss=3.675, pp=39.44, acc=0.377177 [time per itr] 152.92ms [lr] 0.00029
0/71400 [train] loss=3.634 [val] loss=3.645, pp=38.28, acc=0.381091 [time per itr] 152.55ms [lr] 0.00029
0/71600 [train] loss=3.507 [val] loss=3.657, pp=38.75, acc=0.381851 [time per itr] 152.60ms [lr] 0.00028
0/71800 [train] loss=3.547 [val] loss=3.634, pp=37.85, acc=0.387255 [time per itr] 153.00ms [lr] 0.00028
0/72000 [train] loss=3.910 [val] loss=3.649, pp=38.42, acc=0.383357 [time per itr] 152.53ms [lr] 0.00028
0/72200 [train] loss=3.508 [val] loss=3.591, pp=36.28, acc=0.391289 [time per itr] 152.53ms [lr] 0.00028
0/72400 [train] loss=3.728 [val] loss=3.645, pp=38.28, acc=0.382604 [time per itr] 152.49ms [lr] 0.00027
0/72600 [train] loss=3.764 [val] loss=3.605, pp=36.78, acc=0.386225 [time per itr] 152.88ms [lr] 0.00027
0/72800 [train] loss=3.710 [val] loss=3.656, pp=38.71, acc=0.379387 [time per itr] 152.11ms [lr] 0.00027
0/73000 [train] loss=3.597 [val] loss=3.594, pp=36.39, acc=0.389498 [time per itr] 151.82ms [lr] 0.00027
0/73200 [train] loss=3.731 [val] loss=3.638, pp=38.03, acc=0.382802 [time per itr] 154.36ms [lr] 0.00027
0/73400 [train] loss=3.549 [val] loss=3.643, pp=38.22, acc=0.379186 [time per itr] 160.01ms [lr] 0.00026
0/73600 [train] loss=3.699 [val] loss=3.613, pp=37.10, acc=0.388344 [time per itr] 151.91ms [lr] 0.00026
0/73800 [train] loss=3.272 [val] loss=3.558, pp=35.08, acc=0.392497 [time per itr] 152.52ms [lr] 0.00026
0/74000 [train] loss=3.435 [val] loss=3.670, pp=39.27, acc=0.378332 [time per itr] 152.04ms [lr] 0.00026
0/74200 [train] loss=3.858 [val] loss=3.603, pp=36.69, acc=0.389453 [time per itr] 153.06ms [lr] 0.00025
0/74400 [train] loss=3.802 [val] loss=3.592, pp=36.32, acc=0.389132 [time per itr] 152.85ms [lr] 0.00025
0/74600 [train] loss=3.829 [val] loss=3.663, pp=38.97, acc=0.380753 [time per itr] 154.80ms [lr] 0.00025
0/74800 [train] loss=3.706 [val] loss=3.599, pp=36.58, acc=0.387266 [time per itr] 157.00ms [lr] 0.00025
0/75000 [train] loss=3.749 [val] loss=3.640, pp=38.08, acc=0.383550 [time per itr] 152.18ms [lr] 0.00025
0/75200 [train] loss=3.429 [val] loss=3.577, pp=35.75, acc=0.391541 [time per itr] 160.04ms [lr] 0.00024
0/75400 [train] loss=3.781 [val] loss=3.657, pp=38.76, acc=0.381648 [time per itr] 154.86ms [lr] 0.00024
0/75600 [train] loss=3.738 [val] loss=3.558, pp=35.08, acc=0.393723 [time per itr] 161.11ms [lr] 0.00024
0/75800 [train] loss=3.846 [val] loss=3.558, pp=35.08, acc=0.394224 [time per itr] 151.34ms [lr] 0.00024
0/76000 [train] loss=3.514 [val] loss=3.651, pp=38.50, acc=0.378568 [time per itr] 152.10ms [lr] 0.00023
0/76200 [train] loss=3.588 [val] loss=3.597, pp=36.47, acc=0.388351 [time per itr] 153.95ms [lr] 0.00023
0/76400 [train] loss=3.591 [val] loss=3.589, pp=36.21, acc=0.389969 [time per itr] 152.66ms [lr] 0.00023
0/76600 [train] loss=3.433 [val] loss=3.556, pp=35.04, acc=0.396072 [time per itr] 155.79ms [lr] 0.00023
0/76800 [train] loss=3.277 [val] loss=3.607, pp=36.85, acc=0.388059 [time per itr] 154.35ms [lr] 0.00023
0/77000 [train] loss=3.359 [val] loss=3.602, pp=36.67, acc=0.389130 [time per itr] 160.64ms [lr] 0.00022
0/77200 [train] loss=3.039 [val] loss=3.536, pp=34.31, acc=0.397608 [time per itr] 154.87ms [lr] 0.00022
0/77400 [train] loss=3.632 [val] loss=3.567, pp=35.42, acc=0.390099 [time per itr] 155.61ms [lr] 0.00022
0/77600 [train] loss=3.446 [val] loss=3.593, pp=36.35, acc=0.391095 [time per itr] 157.42ms [lr] 0.00022
0/77800 [train] loss=3.714 [val] loss=3.593, pp=36.35, acc=0.390218 [time per itr] 154.23ms [lr] 0.00022
0/78000 [train] loss=3.351 [val] loss=3.570, pp=35.53, acc=0.393946 [time per itr] 151.93ms [lr] 0.00021
0/78200 [train] loss=3.686 [val] loss=3.539, pp=34.43, acc=0.397748 [time per itr] 152.19ms [lr] 0.00021
0/78400 [train] loss=3.748 [val] loss=3.555, pp=35.00, acc=0.390470 [time per itr] 152.63ms [lr] 0.00021
0/78600 [train] loss=3.269 [val] loss=3.541, pp=34.51, acc=0.395935 [time per itr] 151.98ms [lr] 0.00021
0/78800 [train] loss=3.400 [val] loss=3.593, pp=36.33, acc=0.387255 [time per itr] 152.20ms [lr] 0.00021
0/79000 [train] loss=3.477 [val] loss=3.568, pp=35.44, acc=0.393552 [time per itr] 152.75ms [lr] 0.00020
0/79200 [train] loss=3.674 [val] loss=3.564, pp=35.29, acc=0.391101 [time per itr] 152.14ms [lr] 0.00020
0/79400 [train] loss=3.454 [val] loss=3.559, pp=35.13, acc=0.393298 [time per itr] 151.75ms [lr] 0.00020
0/79600 [train] loss=3.407 [val] loss=3.595, pp=36.41, acc=0.389918 [time per itr] 152.16ms [lr] 0.00020
0/79800 [train] loss=3.640 [val] loss=3.562, pp=35.25, acc=0.393984 [time per itr] 154.37ms [lr] 0.00020
0/80000 [train] loss=3.348 [val] loss=3.595, pp=36.41, acc=0.388334 [time per itr] 157.06ms [lr] 0.00019
0/80200 [train] loss=3.342 [val] loss=3.617, pp=37.22, acc=0.385330 [time per itr] 153.49ms [lr] 0.00019
0/80400 [train] loss=3.302 [val] loss=3.526, pp=33.98, acc=0.398453 [time per itr] 151.96ms [lr] 0.00019
0/80600 [train] loss=3.751 [val] loss=3.509, pp=33.40, acc=0.402011 [time per itr] 152.50ms [lr] 0.00019
0/80800 [train] loss=3.318 [val] loss=3.582, pp=35.93, acc=0.390139 [time per itr] 151.77ms [lr] 0.00019
0/81000 [train] loss=3.813 [val] loss=3.582, pp=35.96, acc=0.388102 [time per itr] 152.20ms [lr] 0.00019
0/81200 [train] loss=3.234 [val] loss=3.587, pp=36.14, acc=0.388458 [time per itr] 152.72ms [lr] 0.00018
0/81400 [train] loss=3.313 [val] loss=3.525, pp=33.95, acc=0.397845 [time per itr] 152.64ms [lr] 0.00018
0/81600 [train] loss=3.507 [val] loss=3.519, pp=33.76, acc=0.398112 [time per itr] 151.79ms [lr] 0.00018
0/81800 [train] loss=3.452 [val] loss=3.538, pp=34.41, acc=0.393590 [time per itr] 151.89ms [lr] 0.00018
0/82000 [train] loss=3.503 [val] loss=3.578, pp=35.79, acc=0.390600 [time per itr] 152.18ms [lr] 0.00018
0/82200 [train] loss=3.672 [val] loss=3.525, pp=33.96, acc=0.398104 [time per itr] 152.66ms [lr] 0.00018
0/82400 [train] loss=3.520 [val] loss=3.496, pp=32.98, acc=0.399656 [time per itr] 152.55ms [lr] 0.00017
0/82600 [train] loss=3.238 [val] loss=3.535, pp=34.30, acc=0.395861 [time per itr] 152.81ms [lr] 0.00017
0/82800 [train] loss=3.455 [val] loss=3.514, pp=33.57, acc=0.398677 [time per itr] 152.26ms [lr] 0.00017
0/83000 [train] loss=3.938 [val] loss=3.524, pp=33.91, acc=0.397049 [time per itr] 152.84ms [lr] 0.00017
0/83200 [train] loss=3.666 [val] loss=3.536, pp=34.33, acc=0.395432 [time per itr] 153.03ms [lr] 0.00017
0/83400 [train] loss=3.224 [val] loss=3.580, pp=35.89, acc=0.390460 [time per itr] 153.17ms [lr] 0.00017
0/83600 [train] loss=3.397 [val] loss=3.526, pp=33.98, acc=0.397453 [time per itr] 179.30ms [lr] 0.00016
0/83800 [train] loss=3.479 [val] loss=3.510, pp=33.44, acc=0.400380 [time per itr] 152.95ms [lr] 0.00016
0/84000 [train] loss=3.567 [val] loss=3.550, pp=34.83, acc=0.393636 [time per itr] 159.85ms [lr] 0.00016
0/84200 [train] loss=3.282 [val] loss=3.503, pp=33.22, acc=0.399724 [time per itr] 152.94ms [lr] 0.00016
0/84400 [train] loss=3.483 [val] loss=3.518, pp=33.73, acc=0.396792 [time per itr] 151.57ms [lr] 0.00016
0/84600 [train] loss=3.386 [val] loss=3.546, pp=34.69, acc=0.393982 [time per itr] 151.52ms [lr] 0.00016
0/84800 [train] loss=3.089 [val] loss=3.530, pp=34.12, acc=0.396055 [time per itr] 152.93ms [lr] 0.00016
0/85000 [train] loss=3.640 [val] loss=3.547, pp=34.72, acc=0.393626 [time per itr] 157.76ms [lr] 0.00015
0/85200 [train] loss=3.079 [val] loss=3.563, pp=35.28, acc=0.392782 [time per itr] 156.63ms [lr] 0.00015
0/85400 [train] loss=3.639 [val] loss=3.524, pp=33.91, acc=0.397781 [time per itr] 154.28ms [lr] 0.00015
0/85600 [train] loss=3.704 [val] loss=3.546, pp=34.66, acc=0.392606 [time per itr] 153.40ms [lr] 0.00015
0/85800 [train] loss=3.454 [val] loss=3.470, pp=32.12, acc=0.405525 [time per itr] 151.48ms [lr] 0.00015
0/86000 [train] loss=3.518 [val] loss=3.506, pp=33.31, acc=0.397677 [time per itr] 151.61ms [lr] 0.00015
0/86200 [train] loss=3.399 [val] loss=3.518, pp=33.71, acc=0.396469 [time per itr] 152.07ms [lr] 0.00015
0/86400 [train] loss=3.629 [val] loss=3.482, pp=32.54, acc=0.401825 [time per itr] 152.21ms [lr] 0.00014
0/86600 [train] loss=3.472 [val] loss=3.471, pp=32.16, acc=0.403933 [time per itr] 152.26ms [lr] 0.00014
0/86800 [train] loss=3.792 [val] loss=3.499, pp=33.08, acc=0.397741 [time per itr] 151.65ms [lr] 0.00014
0/87000 [train] loss=3.423 [val] loss=3.534, pp=34.26, acc=0.393232 [time per itr] 157.40ms [lr] 0.00014
0/87200 [train] loss=3.586 [val] loss=3.553, pp=34.92, acc=0.390991 [time per itr] 160.20ms [lr] 0.00014
0/87400 [train] loss=3.388 [val] loss=3.483, pp=32.55, acc=0.405678 [time per itr] 152.27ms [lr] 0.00014
0/87600 [train] loss=3.562 [val] loss=3.518, pp=33.72, acc=0.396136 [time per itr] 152.29ms [lr] 0.00014
0/87800 [train] loss=3.327 [val] loss=3.490, pp=32.80, acc=0.401461 [time per itr] 152.46ms [lr] 0.00014
0/88000 [train] loss=3.752 [val] loss=3.484, pp=32.60, acc=0.401683 [time per itr] 154.36ms [lr] 0.00013
0/88200 [train] loss=3.332 [val] loss=3.520, pp=33.78, acc=0.394333 [time per itr] 168.95ms [lr] 0.00013
0/88400 [train] loss=3.209 [val] loss=3.473, pp=32.23, acc=0.405248 [time per itr] 154.93ms [lr] 0.00013
0/88600 [train] loss=3.519 [val] loss=3.535, pp=34.30, acc=0.393626 [time per itr] 153.43ms [lr] 0.00013
0/88800 [train] loss=3.327 [val] loss=3.464, pp=31.93, acc=0.402710 [time per itr] 156.81ms [lr] 0.00013
0/89000 [train] loss=3.593 [val] loss=3.515, pp=33.60, acc=0.396304 [time per itr] 155.89ms [lr] 0.00013
0/89200 [train] loss=3.275 [val] loss=3.500, pp=33.11, acc=0.397212 [time per itr] 152.26ms [lr] 0.00013
0/89400 [train] loss=3.543 [val] loss=3.484, pp=32.59, acc=0.403804 [time per itr] 152.07ms [lr] 0.00013
0/89600 [train] loss=3.574 [val] loss=3.521, pp=33.81, acc=0.397753 [time per itr] 154.80ms [lr] 0.00013
0/89800 [train] loss=3.457 [val] loss=3.473, pp=32.22, acc=0.402875 [time per itr] 152.55ms [lr] 0.00013
0/90000 [train] loss=3.358 [val] loss=3.475, pp=32.28, acc=0.402311 [time per itr] 152.15ms [lr] 0.00012
0/90200 [train] loss=3.252 [val] loss=3.474, pp=32.26, acc=0.403781 [time per itr] 151.80ms [lr] 0.00012
0/90400 [train] loss=3.646 [val] loss=3.544, pp=34.60, acc=0.396667 [time per itr] 151.58ms [lr] 0.00012
0/90600 [train] loss=3.284 [val] loss=3.446, pp=31.38, acc=0.407293 [time per itr] 152.33ms [lr] 0.00012
0/90800 [train] loss=3.529 [val] loss=3.469, pp=32.12, acc=0.403715 [time per itr] 152.60ms [lr] 0.00012
0/91000 [train] loss=3.355 [val] loss=3.502, pp=33.19, acc=0.398643 [time per itr] 152.79ms [lr] 0.00012
0/91200 [train] loss=3.547 [val] loss=3.499, pp=33.07, acc=0.400963 [time per itr] 154.69ms [lr] 0.00012
0/91400 [train] loss=3.412 [val] loss=3.533, pp=34.23, acc=0.396299 [time per itr] 158.05ms [lr] 0.00012
0/91600 [train] loss=3.277 [val] loss=3.493, pp=32.89, acc=0.399429 [time per itr] 152.79ms [lr] 0.00012
0/91800 [train] loss=3.707 [val] loss=3.440, pp=31.18, acc=0.406601 [time per itr] 178.16ms [lr] 0.00012
0/92000 [train] loss=3.436 [val] loss=3.476, pp=32.32, acc=0.403684 [time per itr] 155.41ms [lr] 0.00012
0/92200 [train] loss=3.382 [val] loss=3.535, pp=34.29, acc=0.392921 [time per itr] 152.11ms [lr] 0.00011
0/92400 [train] loss=3.506 [val] loss=3.517, pp=33.68, acc=0.398008 [time per itr] 152.80ms [lr] 0.00011
0/92600 [train] loss=3.371 [val] loss=3.476, pp=32.34, acc=0.404574 [time per itr] 152.89ms [lr] 0.00011
0/92800 [train] loss=3.575 [val] loss=3.485, pp=32.61, acc=0.401443 [time per itr] 152.28ms [lr] 0.00011
0/93000 [train] loss=3.519 [val] loss=3.448, pp=31.45, acc=0.407646 [time per itr] 151.91ms [lr] 0.00011
0/93200 [train] loss=3.585 [val] loss=3.496, pp=32.97, acc=0.399635 [time per itr] 152.08ms [lr] 0.00011
0/93400 [train] loss=3.383 [val] loss=3.447, pp=31.41, acc=0.404966 [time per itr] 152.06ms [lr] 0.00011
0/93600 [train] loss=3.304 [val] loss=3.500, pp=33.12, acc=0.401072 [time per itr] 152.83ms [lr] 0.00011
0/93800 [train] loss=3.550 [val] loss=3.479, pp=32.42, acc=0.403959 [time per itr] 152.22ms [lr] 0.00011
0/94000 [train] loss=3.465 [val] loss=3.531, pp=34.14, acc=0.397779 [time per itr] 152.56ms [lr] 0.00011
0/94200 [train] loss=3.650 [val] loss=3.477, pp=32.36, acc=0.402730 [time per itr] 152.04ms [lr] 0.00011
0/94400 [train] loss=3.438 [val] loss=3.508, pp=33.37, acc=0.400808 [time per itr] 152.24ms [lr] 0.00011
0/94600 [train] loss=3.469 [val] loss=3.462, pp=31.88, acc=0.403834 [time per itr] 152.58ms [lr] 0.00011
0/94800 [train] loss=3.752 [val] loss=3.517, pp=33.70, acc=0.396172 [time per itr] 153.18ms [lr] 0.00011
0/95000 [train] loss=3.434 [val] loss=3.411, pp=30.28, acc=0.411552 [time per itr] 151.94ms [lr] 0.00011
0/95200 [train] loss=3.299 [val] loss=3.503, pp=33.22, acc=0.401545 [time per itr] 157.11ms [lr] 0.00011
0/95400 [train] loss=3.087 [val] loss=3.467, pp=32.03, acc=0.403816 [time per itr] 159.10ms [lr] 0.00011
0/95600 [train] loss=3.162 [val] loss=3.482, pp=32.52, acc=0.399541 [time per itr] 160.04ms [lr] 0.00010
0/95800 [train] loss=3.476 [val] loss=3.445, pp=31.35, acc=0.408836 [time per itr] 152.22ms [lr] 0.00010
0/96000 [train] loss=3.484 [val] loss=3.448, pp=31.43, acc=0.404556 [time per itr] 153.26ms [lr] 0.00010
0/96200 [train] loss=3.268 [val] loss=3.459, pp=31.78, acc=0.403943 [time per itr] 152.53ms [lr] 0.00010
0/96400 [train] loss=3.413 [val] loss=3.498, pp=33.04, acc=0.397690 [time per itr] 154.27ms [lr] 0.00010
0/96600 [train] loss=3.302 [val] loss=3.458, pp=31.76, acc=0.407583 [time per itr] 165.96ms [lr] 0.00010
0/96800 [train] loss=3.800 [val] loss=3.448, pp=31.44, acc=0.406275 [time per itr] 151.84ms [lr] 0.00010
0/97000 [train] loss=3.121 [val] loss=3.488, pp=32.73, acc=0.399226 [time per itr] 155.24ms [lr] 0.00010
0/97200 [train] loss=3.253 [val] loss=3.488, pp=32.73, acc=0.400304 [time per itr] 154.35ms [lr] 0.00010
0/97400 [train] loss=3.283 [val] loss=3.483, pp=32.55, acc=0.405258 [time per itr] 152.91ms [lr] 0.00010
0/97600 [train] loss=3.748 [val] loss=3.452, pp=31.57, acc=0.405075 [time per itr] 152.85ms [lr] 0.00010
0/97800 [train] loss=3.301 [val] loss=3.451, pp=31.54, acc=0.407542 [time per itr] 152.86ms [lr] 0.00010
0/98000 [train] loss=3.417 [val] loss=3.445, pp=31.34, acc=0.406848 [time per itr] 152.57ms [lr] 0.00010
0/98200 [train] loss=3.857 [val] loss=3.476, pp=32.34, acc=0.403165 [time per itr] 152.69ms [lr] 0.00010
0/98400 [train] loss=3.907 [val] loss=3.480, pp=32.47, acc=0.399839 [time per itr] 152.52ms [lr] 0.00010
0/98600 [train] loss=3.402 [val] loss=3.472, pp=32.20, acc=0.402857 [time per itr] 152.28ms [lr] 0.00010
0/98800 [train] loss=3.425 [val] loss=3.474, pp=32.27, acc=0.405388 [time per itr] 153.04ms [lr] 0.00010
0/99000 [train] loss=3.366 [val] loss=3.477, pp=32.37, acc=0.400302 [time per itr] 152.20ms [lr] 0.00010
0/99200 [train] loss=3.070 [val] loss=3.472, pp=32.20, acc=0.403666 [time per itr] 152.56ms [lr] 0.00010
0/99400 [train] loss=3.219 [val] loss=3.465, pp=31.98, acc=0.403776 [time per itr] 153.73ms [lr] 0.00010
0/99600 [train] loss=3.440 [val] loss=3.472, pp=32.21, acc=0.405609 [time per itr] 153.51ms [lr] 0.00010
0/99800 [train] loss=3.140 [val] loss=3.508, pp=33.38, acc=0.401016 [time per itr] 172.49ms [lr] 0.00010
0/100000 [train] loss=3.271 [val] loss=3.467, pp=32.03, acc=0.403577 [time per itr] 152.58ms [lr] 0.00010
saving checkpoint to ./exps/slimpajama/base/base_lr0.001_bs32x4_seqlen512/run_id=20250915_222348_seed=0/20250915_222348/ckpt.pt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mbase_lr0.001_bs32x4_seqlen512/run_id=20250915_222348_seed=0[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250915_222529-noiou2md/logs[0m
